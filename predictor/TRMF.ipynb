{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this Notebook\n",
    "\n",
    "Temporal Regularized Matrix Factorization (TRMF) is an effective tool for imputing missing data within a given multivariate time series and forecasting time series with missing values. This approach is from the following literature:\n",
    "\n",
    "> Hsiang-Fu Yu, Nikhil Rao, Inderjit S. Dhillon, 2016. [**Temporal regularized matrix factorization for high-dimensional time series prediction**](http://www.cs.utexas.edu/~rofuyu/papers/tr-mf-nips.pdf). 30th Conference on Neural Information Processing Systems (*NIPS 2016*), Barcelona, Spain.\n",
    "\n",
    "**Acknowledgement**: We would like to thank\n",
    "\n",
    "- Antony Masso Lussier (HEC Montreal)\n",
    "\n",
    "for providing helpful suggestion and discussion. Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Run\n",
    "\n",
    "This notebook is publicly available for any usage at our data imputation project. Please click [**transdim**](https://github.com/xinychen/transdim).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Organization: Matrix Structure\n",
    "\n",
    "In this post, we consider a dataset of $m$ discrete time series $\\boldsymbol{y}_{i}\\in\\mathbb{R}^{f},i\\in\\left\\{1,2,...,m\\right\\}$. The time series may have missing elements. We express spatio-temporal dataset as a matrix $Y\\in\\mathbb{R}^{m\\times f}$ with $m$ rows (e.g., locations) and $f$ columns (e.g., discrete time intervals),\n",
    "\n",
    "$$Y=\\left[ \\begin{array}{cccc} y_{11} & y_{12} & \\cdots & y_{1f} \\\\ y_{21} & y_{22} & \\cdots & y_{2f} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ y_{m1} & y_{m2} & \\cdots & y_{mf} \\\\ \\end{array} \\right]\\in\\mathbb{R}^{m\\times f}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TRMF model\n",
    "\n",
    "Temporal Regularized Matrix Factorization (TRMF) is an approach to incorporate temporal dependencies into commonly-used matrix factorization model. The temporal dependencies are described among ${\\boldsymbol{x}_t}$ explicitly. Such approach takes the form:\n",
    "\n",
    "$$\\boldsymbol{x}_{t}\\approx\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l},$$\n",
    "where this autoregressive (AR) is specialized by a lag set $\\mathcal{L}=\\left\\{l_1,l_2,...,l_d\\right\\}$ (e.g., $\\mathcal{L}=\\left\\{1,2,144\\right\\}$) and weights $\\boldsymbol{\\theta}_{l}\\in\\mathbb{R}^{r},\\forall l$, and we further define\n",
    "\n",
    "$$\\mathcal{R}_{AR}\\left(X\\mid \\mathcal{L},\\Theta,\\eta\\right)=\\frac{1}{2}\\sum_{t=l_d+1}^{f}\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)^\\top\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)+\\frac{\\eta}{2}\\sum_{t=1}^{f}\\boldsymbol{x}_{t}^\\top\\boldsymbol{x}_{t}.$$\n",
    "\n",
    "Thus, TRMF-AR is given by solving\n",
    "\n",
    "$$\\min_{W,X,\\Theta}\\frac{1}{2}\\underbrace{\\sum_{(i,t)\\in\\Omega}\\left(y_{it}-\\boldsymbol{w}_{i}^T\\boldsymbol{x}_{t}\\right)^2}_{\\text{sum of squared residual errors}}+\\lambda_{w}\\underbrace{\\mathcal{R}_{w}\\left(W\\right)}_{W-\\text{regularizer}}+\\lambda_{x}\\underbrace{\\mathcal{R}_{AR}\\left(X\\mid \\mathcal{L},\\Theta,\\eta\\right)}_{\\text{AR-regularizer}}+\\lambda_{\\theta}\\underbrace{\\mathcal{R}_{\\theta}\\left(\\Theta\\right)}_{\\Theta-\\text{regularizer}}$$\n",
    "\n",
    "where $\\mathcal{R}_{w}\\left(W\\right)=\\frac{1}{2}\\sum_{i=1}^{m}\\boldsymbol{w}_{i}^\\top\\boldsymbol{w}_{i}$ and $\\mathcal{R}_{\\theta}\\left(\\Theta\\right)=\\frac{1}{2}\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}^\\top\\boldsymbol{\\theta}_{l}$ are regularization terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define TRMF model with `Numpy`\n",
    "\n",
    "Observing the optimization problem of TRMF model as mentioned above, we categorize the parameters within this model as **parameters** (i.e., `init_para` in the TRMF function) and **hyperparameters** (i.e., `init_hyper`).\n",
    "\n",
    "- **Parameters** include spatial matrix $W$, temporal matrix $X$, and AR coefficients $\\Theta$.\n",
    "- **Hyperparameters** include weight parameters on some regularizers, i.e., $\\lambda_w$, $\\lambda_x$, $\\lambda_\\theta$, and $\\eta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to understand Python code of TRMF?\n",
    "\n",
    "#### Update spatial matrix $W$\n",
    "\n",
    "We write Python code for updating spatial matrix as follows,\n",
    "\n",
    "```python\n",
    "for i in range(dim1):\n",
    "    pos0 = np.where(sparse_mat[i, :] != 0)\n",
    "    Xt = X[pos0[0], :]\n",
    "    vec0 = Xt.T @ sparse_mat[i, pos0[0]]\n",
    "    mat0 = inv(Xt.T @ Xt + lambda_w * np.eye(rank))\n",
    "    W[i, :] = mat0 @ vec0\n",
    "```\n",
    "\n",
    "For your better understanding of these codes, let us see what happened in each line. Recall that the equation for updating $W$ is\n",
    "$$\\boldsymbol{w}_{i} \\Leftarrow\\left(\\sum_{t:(i, t) \\in \\Omega} \\boldsymbol{x}_{t} \\boldsymbol{x}_{t}^{T}+\\lambda_{w} I\\right)^{-1} \\sum_{t:(i, t) \\in \\Omega} y_{i t} \\boldsymbol{x}_{t}$$\n",
    "from the optimizization problem:\n",
    "$$\\min _{W} \\frac{1}{2} \\underbrace{\\sum_{(i, t) \\in \\Omega}\\left(y_{i t}-\\boldsymbol{w}_{i}^{T} \\boldsymbol{x}_{t}\\right)^{2}}_{\\text {sum of squared residual errors }}+\\frac{1}{2} \\lambda_{w} \\underbrace{\\sum_{i=1}^{m} \\boldsymbol{w}_{i}^{T} \\boldsymbol{w}_{i}}_{\\text{sum of squared entries}}.$$\n",
    "\n",
    "As can be seen,\n",
    "\n",
    "- `vec0 = Xt.T @ sparse_mat[i, pos0[0]])` corresponds to $$\\sum_{t:(i, t) \\in \\Omega} y_{i t} \\boldsymbol{x}_{t}.$$\n",
    "\n",
    "- `mat0 = inv(Xt.T @ Xt + lambda_w * np.eye(rank))` corresponds to $$\\left(\\sum_{t:(i, t) \\in \\Omega} \\boldsymbol{x}_{t} \\boldsymbol{x}_{t}^{T}+\\lambda_{w} I\\right)^{-1}.$$\n",
    "\n",
    "- `W[i, :] = mat0 @ vec0` corresponds to the update:\n",
    "$$\\boldsymbol{w}_{i} \\Leftarrow\\left(\\sum_{t:(i, t) \\in \\Omega} \\boldsymbol{x}_{t} \\boldsymbol{x}_{t}^{T}+\\lambda_{w} I\\right)^{-1} \\sum_{t:(i, t) \\in \\Omega} y_{i t} \\boldsymbol{x}_{t}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update temporal matrix $X$\n",
    "\n",
    "We write Python code for updating temporal matrix as follows,\n",
    "\n",
    "```python\n",
    "for t in range(dim2):\n",
    "    pos0 = np.where(sparse_mat[:, t] != 0)\n",
    "    Wt = W[pos0[0], :]\n",
    "    Mt = np.zeros((rank, rank))\n",
    "    Nt = np.zeros(rank)\n",
    "    if t < np.max(time_lags):\n",
    "        Pt = np.zeros((rank, rank))\n",
    "        Qt = np.zeros(rank)\n",
    "    else:\n",
    "        Pt = np.eye(rank)\n",
    "        Qt = np.einsum('ij, ij -> j', theta, X[t - time_lags, :])\n",
    "    if t < dim2 - np.min(time_lags):\n",
    "        if t >= np.max(time_lags) and t < dim2 - np.max(time_lags):\n",
    "            index = list(range(0, d))\n",
    "        else:\n",
    "            index = list(np.where((t + time_lags >= np.max(time_lags)) & (t + time_lags < dim2)))[0]\n",
    "        for k in index:\n",
    "            Ak = theta[k, :]\n",
    "            Mt += np.diag(Ak ** 2)\n",
    "            theta0 = theta.copy()\n",
    "            theta0[k, :] = 0\n",
    "            Nt += np.multiply(Ak, X[t + time_lags[k], :]\n",
    "                              - np.einsum('ij, ij -> j', theta0, X[t + time_lags[k] - time_lags, :]))\n",
    "    vec0 = Wt.T @ sparse_mat[pos0[0], t] + lambda_x * Nt + lambda_x * Qt\n",
    "    mat0 = inv(Wt.T @ Wt + lambda_x * Mt + lambda_x * Pt + lambda_x * eta * np.eye(rank))\n",
    "    X[t, :] = mat0 @ vec0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These codes seem to be very complicated. Let us first see the optimization problem for getting a closed-form update of $X$:\n",
    "$$\\min_{W,X,\\Theta}\\frac{1}{2}\\underbrace{\\sum_{(i,t)\\in\\Omega}\\left(y_{it}-\\boldsymbol{w}_{i}^T\\boldsymbol{x}_{t}\\right)^2}_{\\text{sum of squared residual errors}}+\\underbrace{\\frac{1}{2}\\lambda_{x}\\sum_{t=l_d+1}^{f}\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)^\\top\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)+\\frac{1}{2}\\lambda_{x}\\eta\\sum_{t=1}^{f}\\boldsymbol{x}_{t}^\\top\\boldsymbol{x}_{t}}_{\\text{AR-term}}+\\underbrace{\\frac{1}{2}\\lambda_{\\theta}\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}^\\top\\boldsymbol{\\theta}_{l}}_{\\Theta-\\text{term}}.$$\n",
    "\n",
    "- For $t=1,...,l_d$, update of $X$ is\n",
    "$$\\boldsymbol{x}_{t} \\Leftarrow\\left(\\sum_{i:(i, t) \\in \\Omega} \\boldsymbol{w}_{i} \\boldsymbol{w}_{i}^{T}+\\lambda_{x} \\eta I\\right)^{-1} \\sum_{i:(i, t) \\in \\Omega} y_{i t} \\boldsymbol{w}_{i}.$$\n",
    "- For $t=l_d+1,...,f$, update of $X$ is\n",
    "$${\\boldsymbol{x}_{t}\\Leftarrow\\left(\\sum_{i:(i,t)\\in\\Omega}\\boldsymbol{w}_{i}\\boldsymbol{w}_{i}^{T}+\\lambda_xI+\\lambda_x\\sum_{h\\in\\mathcal{L},t+h \\leq T}\\text{diag}(\\boldsymbol{\\theta}_{h}\\circledast\\boldsymbol{\\theta}_{h})+\\lambda_x\\eta I\\right)^{-1}}{\\left(\\sum_{i:(i,t)\\in\\Omega}y_{it}\\boldsymbol{w}_{i}+\\lambda_x\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}+\\lambda_x\\sum_{h\\in\\mathcal{L},t+h \\leq T}\\boldsymbol{\\theta}_{h}\\circledast\\boldsymbol{\\psi}_{t+h}\\right)}.$$\n",
    "\n",
    "Then, as can be seen,\n",
    "\n",
    "- `Mt += np.diag(Ak ** 2)` corresponds to $$\\sum_{h\\in\\mathcal{L},t+h \\leq T}\\text{diag}(\\boldsymbol{\\theta}_{h}\\circledast\\boldsymbol{\\theta}_{h}).$$\n",
    "\n",
    "- `Nt += np.multiply(Ak, X[t + time_lags[k], :] - np.einsum('ij, ij -> j', theta0, X[t + time_lags[k] - time_lags, :]))` corresponds to $$\\sum_{h\\in\\mathcal{L},t+h \\leq T}\\boldsymbol{\\theta}_{h}\\circledast\\boldsymbol{\\psi}_{t+h}.$$\n",
    "\n",
    "- `Qt = np.einsum('ij, ij -> j', theta, X[t - time_lags, :])` corresponds to $$\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}.$$\n",
    "-`X[t, :] = mat0 @ vec0` corresponds to the update of $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update AR coefficients $\\Theta$\n",
    "\n",
    "We write Python code for updating temporal matrix as follows,\n",
    "\n",
    "```python\n",
    "for k in range(d):\n",
    "    theta0 = theta.copy()\n",
    "    theta0[k, :] = 0\n",
    "    mat0 = np.zeros((dim2 - np.max(time_lags), rank))\n",
    "    for L in range(d):\n",
    "        mat0 += X[np.max(time_lags) - time_lags[L] : dim2 - time_lags[L] , :] @ np.diag(theta0[L, :])\n",
    "    VarPi = X[np.max(time_lags) : dim2, :] - mat0\n",
    "    var1 = np.zeros((rank, rank))\n",
    "    var2 = np.zeros(rank)\n",
    "    for t in range(np.max(time_lags), dim2):\n",
    "        B = X[t - time_lags[k], :]\n",
    "        var1 += np.diag(np.multiply(B, B))\n",
    "        var2 += np.diag(B) @ VarPi[t - np.max(time_lags), :]\n",
    "    theta[k, :] = inv(var1 + lambda_theta * np.eye(rank) / lambda_x) @ var2\n",
    "```\n",
    "\n",
    "For your better understanding of these codes, let us see what happened in each line. Recall that the equation for updating $\\theta$ is\n",
    "$$\n",
    "\\color{red} {\\boldsymbol{\\theta}_{h}\\Leftarrow\\left(\\sum_{t=l_d+1}^{f}\\text{diag}(\\boldsymbol{x}_{t-h}\\circledast \\boldsymbol{x}_{t-h})+\\frac{\\lambda_{\\theta}}{\\lambda_x}I\\right)^{-1}\\left(\\sum_{t=l_d+1}^{f}{\\boldsymbol{\\pi}_{t}^{h}}\\circledast \\boldsymbol{x}_{t-h}\\right)}\n",
    "$$\n",
    "where $\\boldsymbol{\\pi}_{t}^{h}=\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L},l\\neq h}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}$ from the optimizization problem:\n",
    "$$\n",
    "\\min_{\\Theta}\\frac{1}{2}\\lambda_{x}\\underbrace{\\sum_{t=l_d+1}^{f}\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)^\\top\\left(\\boldsymbol{x}_{t}-\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}\\right)}_{\\text{sum of squared residual errors}}+\\frac{1}{2}\\lambda_{\\theta}\\underbrace{\\sum_{l\\in\\mathcal{L}}\\boldsymbol{\\theta}_{l}^\\top\\boldsymbol{\\theta}_{l}}_{\\text{sum of squared entries}}\n",
    "$$\n",
    "\n",
    "As can be seen,\n",
    "- `mat0 += X[np.max(time_lags) - time_lags[L] : dim2 - time_lags[L] , :] @ np.diag(theta0[L, :])` corresponds to $$\\sum_{l\\in\\mathcal{L},l\\neq h}\\boldsymbol{\\theta}_{l}\\circledast\\boldsymbol{x}_{t-l}$$.\n",
    "\n",
    "- `var1 += np.diag(np.multiply(B, B))` corresponds to $$\\sum_{t=l_d+1}^{f}\\text{diag}(\\boldsymbol{x}_{t-h}\\circledast \\boldsymbol{x}_{t-h}).$$\n",
    "\n",
    "- `var2 += np.diag(B) @ VarPi[t - np.max(time_lags), :]` corresponds to $$\\sum_{t=l_d+1}^{f}{\\boldsymbol{\\pi}_{t}^{h}}\\circledast \\boldsymbol{x}_{t-h}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ar4cast(theta, X, time_lags, multi_step):\n",
    "    dim, rank = X.shape\n",
    "    d = time_lags.shape[0]\n",
    "    X_new = np.append(X, np.zeros((multi_step, rank)), axis = 0)\n",
    "    for t in range(multi_step):\n",
    "        X_new[dim + t, :] = np.einsum('kr, kr -> r', theta, X_new[dim + t - time_lags, :])\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return  np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv as inv\n",
    "\n",
    "\n",
    "def TRMF(dense_mat, sparse_mat, init_para, init_hyper, time_lags, maxiter):\n",
    "    \"\"\"Temporal Regularized Matrix Factorization, TRMF.\"\"\"\n",
    "    \n",
    "    ## Initialize parameters\n",
    "    W = init_para[\"W\"]\n",
    "    X = init_para[\"X\"]\n",
    "    theta = init_para[\"theta\"]\n",
    "    \n",
    "    ## Set hyperparameters\n",
    "    lambda_w = init_hyper[\"lambda_w\"]\n",
    "    lambda_x = init_hyper[\"lambda_x\"]\n",
    "    lambda_theta = init_hyper[\"lambda_theta\"]\n",
    "    eta = init_hyper[\"eta\"]\n",
    "    \n",
    "    dim1, dim2 = sparse_mat.shape\n",
    "    pos_train = np.where(sparse_mat != 0)\n",
    "    pos_test = np.where((dense_mat != 0) & (sparse_mat == 0))\n",
    "    binary_mat = sparse_mat.copy()\n",
    "    binary_mat[pos_train] = 1\n",
    "    d, rank = theta.shape\n",
    "    \n",
    "    for it in range(maxiter):\n",
    "        ## Update spatial matrix W\n",
    "        for i in range(dim1):\n",
    "            pos0 = np.where(sparse_mat[i, :] != 0)\n",
    "            Xt = X[pos0[0], :]\n",
    "            vec0 = Xt.T @ sparse_mat[i, pos0[0]]\n",
    "            mat0 = inv(Xt.T @ Xt + lambda_w * np.eye(rank))\n",
    "            W[i, :] = mat0 @ vec0\n",
    "        ## Update temporal matrix X\n",
    "        for t in range(dim2):\n",
    "            pos0 = np.where(sparse_mat[:, t] != 0)\n",
    "            Wt = W[pos0[0], :]\n",
    "            Mt = np.zeros((rank, rank))\n",
    "            Nt = np.zeros(rank)\n",
    "            if t < np.max(time_lags):\n",
    "                Pt = np.zeros((rank, rank))\n",
    "                Qt = np.zeros(rank)\n",
    "            else:\n",
    "                Pt = np.eye(rank)\n",
    "                Qt = np.einsum('ij, ij -> j', theta, X[t - time_lags, :])\n",
    "            if t < dim2 - np.min(time_lags):\n",
    "                if t >= np.max(time_lags) and t < dim2 - np.max(time_lags):\n",
    "                    index = list(range(0, d))\n",
    "                else:\n",
    "                    index = list(np.where((t + time_lags >= np.max(time_lags)) & (t + time_lags < dim2)))[0]\n",
    "                for k in index:\n",
    "                    Ak = theta[k, :]\n",
    "                    Mt += np.diag(Ak ** 2)\n",
    "                    theta0 = theta.copy()\n",
    "                    theta0[k, :] = 0\n",
    "                    Nt += np.multiply(Ak, X[t + time_lags[k], :]\n",
    "                                      - np.einsum('ij, ij -> j', theta0, X[t + time_lags[k] - time_lags, :]))\n",
    "            vec0 = Wt.T @ sparse_mat[pos0[0], t] + lambda_x * Nt + lambda_x * Qt\n",
    "            mat0 = inv(Wt.T @ Wt + lambda_x * Mt + lambda_x * Pt + lambda_x * eta * np.eye(rank))\n",
    "            X[t, :] = mat0 @ vec0\n",
    "        ## Update AR coefficients theta\n",
    "        for k in range(d):\n",
    "            theta0 = theta.copy()\n",
    "            theta0[k, :] = 0\n",
    "            mat0 = np.zeros((dim2 - np.max(time_lags), rank))\n",
    "            for L in range(d):\n",
    "                mat0 += X[np.max(time_lags) - time_lags[L] : dim2 - time_lags[L] , :] @ np.diag(theta0[L, :])\n",
    "            VarPi = X[np.max(time_lags) : dim2, :] - mat0\n",
    "            var1 = np.zeros((rank, rank))\n",
    "            var2 = np.zeros(rank)\n",
    "            for t in range(np.max(time_lags), dim2):\n",
    "                B = X[t - time_lags[k], :]\n",
    "                var1 += np.diag(np.multiply(B, B))\n",
    "                var2 += np.diag(B) @ VarPi[t - np.max(time_lags), :]\n",
    "            theta[k, :] = inv(var1 + lambda_theta * np.eye(rank) / lambda_x) @ var2\n",
    "\n",
    "        X_new = ar4cast(theta, X, time_lags, multi_step)\n",
    "        mat_new = W @ X_new[- multi_step :, :].T\n",
    "        mat_hat = W @ X.T\n",
    "        mape = np.sum(np.abs(dense_mat[pos_test] - mat_hat[pos_test]) \n",
    "                      / dense_mat[pos_test]) / dense_mat[pos_test].shape[0]\n",
    "        rmse = np.sqrt(np.sum((dense_mat[pos_test] - mat_hat[pos_test]) ** 2)/dense_mat[pos_test].shape[0])\n",
    "        \n",
    "        if (it + 1) % 100 == 0:\n",
    "            print('Iter: {}'.format(it + 1))\n",
    "            print('Imputation MAPE: {:.6}'.format(mape))\n",
    "            print('Imputation RMSE: {:.6}'.format(rmse))\n",
    "            print()\n",
    "    mat_hat = np.append(mat_hat, mat_new, axis = 1)\n",
    "    \n",
    "    return mat_hat, W, X_new, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_x_partial(sparse_mat, W, X, theta, lambda_x, eta, time_lags, back_step):\n",
    "    \n",
    "    dim2, rank = X.shape\n",
    "    tmax = np.max(time_lags)\n",
    "    for t in range(dim2 - back_step, dim2):\n",
    "        pos0 = np.where(sparse_mat[:, t] != 0)\n",
    "        Wt = W[pos0[0], :]\n",
    "        Mt = np.zeros((rank, rank))\n",
    "        Nt = np.zeros(rank)\n",
    "        if t < tmax:\n",
    "            Pt = np.zeros((rank, rank))\n",
    "            Qt = np.zeros(rank)\n",
    "        else:\n",
    "            Pt = np.eye(rank)\n",
    "            Qt = np.einsum('ij, ij -> j', theta, X[t - time_lags, :])\n",
    "        if t < dim2 - np.min(time_lags):\n",
    "            if t >= tmax and t < dim2 - tmax:\n",
    "                index = list(range(0, d))\n",
    "            else:\n",
    "                index = list(np.where((t + time_lags >= tmax) & (t + time_lags < dim2)))[0]\n",
    "            for k in index:\n",
    "                Ak = theta[k, :]\n",
    "                Mt += np.diag(Ak ** 2)\n",
    "                theta0 = theta.copy()\n",
    "                theta0[k, :] = 0\n",
    "                Nt += np.multiply(Ak, X[t + time_lags[k], :]\n",
    "                                  - np.einsum('ij, ij -> j', theta0, X[t + time_lags[k] - time_lags, :]))\n",
    "        vec0 = Wt.T @ sparse_mat[pos0[0], t] + lambda_x * Nt + lambda_x * Qt\n",
    "        mat0 = inv(Wt.T @ Wt + lambda_x * Mt + lambda_x * Pt + lambda_x * eta * np.eye(rank))\n",
    "        X[t, :] = mat0 @ vec0\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRMF_partial(dense_mat, sparse_mat, init_para, init_hyper, time_lags, maxiter):\n",
    "    \n",
    "    ## Initialize parameters\n",
    "    W = init_para[\"W\"]\n",
    "    X = init_para[\"X\"]\n",
    "    theta = init_para[\"theta\"]\n",
    "    ## Set hyperparameters\n",
    "    lambda_x = init_hyper[\"lambda_x\"]\n",
    "    eta = init_hyper[\"eta\"]    \n",
    "    back_step = 10 * multi_step\n",
    "    for it in range(maxiter):\n",
    "        X = update_x_partial(sparse_mat, W, X, theta, lambda_x, eta, time_lags, back_step)\n",
    "    X_new = ar4cast(theta, X, time_lags, multi_step)\n",
    "    mat_hat = W @ X_new[- multi_step :, :].T\n",
    "    mat_hat[mat_hat < 0] = 0\n",
    "    \n",
    "    return mat_hat, W, X_new, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "def TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter):\n",
    "    dim1, T = dense_mat.shape\n",
    "    d = time_lags.shape[0]\n",
    "    start_time = T - pred_step\n",
    "    max_count = int(np.ceil(pred_step / multi_step))\n",
    "    mat_hat = np.zeros((dim1, max_count * multi_step))\n",
    "    f = IntProgress(min = 0, max = max_count) # instantiate the bar\n",
    "    display(f) # display the bar\n",
    "    for t in range(max_count):\n",
    "        if t == 0:\n",
    "            init_para = {\"W\": 0.1 * np.random.randn(dim1, rank), \n",
    "                         \"X\": 0.1 * np.random.randn(start_time, rank),\n",
    "                         \"theta\": 0.1 * np.random.randn(d, rank)}\n",
    "            mat, W, X_new, theta = TRMF(dense_mat[:, 0 : start_time], sparse_mat[:, 0 : start_time], \n",
    "                                        init_para, init_hyper, time_lags, maxiter)\n",
    "        else:\n",
    "            init_para = {\"W\": W, \"X\": X_new, \"theta\": theta}\n",
    "            mat, W, X_new, theta = TRMF_partial(dense_mat[:, 0 : start_time + t * multi_step], \n",
    "                                                sparse_mat[:, 0 : start_time + t * multi_step], \n",
    "                                                init_para, init_hyper, time_lags, maxiter)\n",
    "        mat_hat[:, t * multi_step : (t + 1) * multi_step] = mat[:, - multi_step :]\n",
    "        f.value = t\n",
    "    small_dense_mat = dense_mat[:, start_time : T]\n",
    "    pos = np.where(small_dense_mat != 0)\n",
    "    print('Prediction MAPE: {:.6}'.format(compute_mape(small_dense_mat[pos], mat_hat[pos])))\n",
    "    print('Prediction RMSE: {:.6}'.format(compute_rmse(small_dense_mat[pos], mat_hat[pos])))\n",
    "    print()\n",
    "    return mat_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Guangzhou Speed Data\n",
    "\n",
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $214\\times 61\\times 144$ (road segment, day, time of day)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')['random_matrix']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_tensor = np.zeros(tensor.shape)\n",
    "for i1 in range(tensor.shape[0]):\n",
    "    for i2 in range(tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] * binary_tensor.shape[2]])\n",
    "sparse_mat = dense_mat * binary_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Time lags: {1, 2, 144}\n",
    "- The number of iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time horizon (delta) = 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc5784af9224a6ab72882c3ff7b92d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=504)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Imputation MAPE: 0.115188\n",
      "Imputation RMSE: 4.6092\n",
      "\n",
      "Iter: 200\n",
      "Imputation MAPE: 0.115174\n",
      "Imputation RMSE: 4.60879\n",
      "\n",
      "Prediction MAPE: 0.127976\n",
      "Prediction RMSE: 4.87849\n",
      "\n",
      "Running time: 1011 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 4.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44dcf12e08a496aac04cb83a2dd6c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=252)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Imputation MAPE: 0.115176\n",
      "Imputation RMSE: 4.60879\n",
      "\n",
      "Iter: 200\n",
      "Imputation MAPE: 0.115166\n",
      "Imputation RMSE: 4.60855\n",
      "\n",
      "Prediction MAPE: 0.128447\n",
      "Prediction RMSE: 4.88498\n",
      "\n",
      "Running time: 1033 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 6.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37013a86d03a476cab31cf2bae5b7de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=168)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Imputation MAPE: 0.115173\n",
      "Imputation RMSE: 4.60868\n",
      "\n",
      "Iter: 200\n",
      "Imputation MAPE: 0.115167\n",
      "Imputation RMSE: 4.60854\n",
      "\n",
      "Prediction MAPE: 0.133175\n",
      "Prediction RMSE: 5.11059\n",
      "\n",
      "Running time: 991 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 144\n",
    "time_lags = np.array([1, 2, 3, 144, 145, 146, 7 * 144, 7 * 144 + 1, 7 * 144 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $214\\times 61\\times 144$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')['random_tensor']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_mat = (np.round(random_tensor + 0.5 - missing_rate)\n",
    "              .reshape([random_tensor.shape[0], random_tensor.shape[1] * random_tensor.shape[2]]))\n",
    "sparse_mat = dense_mat * binary_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Time lags: {1, 2, 144}\n",
    "- The number of iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time horizon (delta) = 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4ca3cc9ea34390aa7f60f667ba8123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=504)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Imputation MAPE: 0.113995\n",
      "Imputation RMSE: 4.56227\n",
      "\n",
      "Iter: 200\n",
      "Imputation MAPE: 0.113972\n",
      "Imputation RMSE: 4.5614\n",
      "\n",
      "Prediction MAPE: 0.127169\n",
      "Prediction RMSE: 4.83963\n",
      "\n",
      "Running time: 1064 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 4.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705521b5f08e4cbd976fa98639b2b4ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=252)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 100\n",
      "Imputation MAPE: 0.113994\n",
      "Imputation RMSE: 4.56227\n",
      "\n",
      "Iter: 200\n",
      "Imputation MAPE: 0.11398\n",
      "Imputation RMSE: 4.56178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 144\n",
    "time_lags = np.array([1, 2, 3, 144, 145, 146, 7 * 144, 7 * 144 + 1, 7 * 144 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $214\\times 61\\times 144$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 60% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')['random_tensor']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.6\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_mat = (np.round(random_tensor + 0.5 - missing_rate)\n",
    "              .reshape([random_tensor.shape[0], random_tensor.shape[1] * random_tensor.shape[2]]))\n",
    "sparse_mat = dense_mat * binary_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 80\n",
    "- Time lags: {1, 2, 144}\n",
    "- The number of iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 144\n",
    "time_lags = np.array([1, 2, 3, 144, 145, 146, 7 * 144, 7 * 144 + 1, 7 * 144 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "sparse_mat = dense_mat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 144\n",
    "time_lags = np.array([1, 2, 3, 144, 145, 146, 7 * 144, 7 * 144 + 1, 7 * 144 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Hangzhou Flow Data\n",
    "\n",
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $80\\times 25\\times 108$ (metro station, day, time of day)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_matrix.mat')['random_matrix']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_tensor = np.zeros(tensor.shape)\n",
    "for i1 in range(tensor.shape[0]):\n",
    "    for i2 in range(tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] * binary_tensor.shape[2]])\n",
    "sparse_mat = dense_mat * binary_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 30\n",
    "- Time lags: {1, 2, 108}\n",
    "- The number of iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 108\n",
    "time_lags = np.array([1, 2, 3, 108, 109, 110, 7 * 108, 7 * 108 + 1, 7 * 108 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $80\\times 25\\times 108$ (metro station, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')['random_tensor']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_mat = (np.round(random_tensor + 0.5 - missing_rate)\n",
    "              .reshape([random_tensor.shape[0], random_tensor.shape[1] * random_tensor.shape[2]]))\n",
    "sparse_mat = dense_mat * binary_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 30\n",
    "- Time lags: {1, 2, 108}\n",
    "- The number of iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 108\n",
    "time_lags = np.array([1, 2, 3, 108, 109, 110, 7 * 108, 7 * 108 + 1, 7 * 108 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $80\\times 25\\times 108$ (metro station, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 60% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')['random_tensor']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.6\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_mat = (np.round(random_tensor + 0.5 - missing_rate)\n",
    "              .reshape([random_tensor.shape[0], random_tensor.shape[1] * random_tensor.shape[2]]))\n",
    "sparse_mat = dense_mat * binary_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 30\n",
    "- Time lags: {1, 2, 108}\n",
    "- The number of iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 108\n",
    "time_lags = np.array([1, 2, 3, 108, 109, 110, 7 * 108, 7 * 108 + 1, 7 * 108 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')['tensor']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "sparse_mat = dense_mat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 108\n",
    "time_lags = np.array([1, 2, 3, 108, 109, 110, 7 * 108, 7 * 108 + 1, 7 * 108 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Seattle Speed Data\n",
    "\n",
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $323\\times 28\\times 288$ (road segment, day, time of day)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "NM_mat = pd.read_csv('../datasets/Seattle-data-set/NM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "NM_mat = NM_mat.values\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 28, 288))\n",
    "for i1 in range(binary_tensor.shape[0]):\n",
    "    for i2 in range(binary_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(NM_mat[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_mat = dense_mat * binary_tensor.reshape([dense_mat.shape[0], dense_mat.shape[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Time lags: {1, 2, 288}\n",
    "- The number of iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 288\n",
    "time_lags = np.array([1, 2, 3, 288, 289, 290, 7 * 288, 7 * 288 + 1, 7 * 288 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $323\\times 28\\times 288$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "RM_mat = pd.read_csv('../datasets/Seattle-data-set/RM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "RM_mat = RM_mat.values\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_mat = np.round(RM_mat + 0.5 - missing_rate)\n",
    "sparse_mat = dense_mat * binary_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 50\n",
    "- Time lags: {1, 2, 288}\n",
    "- The number of iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 288\n",
    "time_lags = np.array([1, 2, 3, 288, 289, 290, 7 * 288, 7 * 288 + 1, 7 * 288 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $323\\times 28\\times 288$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 60% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "RM_mat = pd.read_csv('../datasets/Seattle-data-set/RM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "RM_mat = RM_mat.values\n",
    "missing_rate = 0.6\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_mat = np.round(RM_mat + 0.5 - missing_rate)\n",
    "sparse_mat = dense_mat * binary_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 50\n",
    "- Time lags: {1, 2, 288}\n",
    "- The number of iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 288\n",
    "time_lags = np.array([1, 2, 3, 288, 289, 290, 7 * 288, 7 * 288 + 1, 7 * 288 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "sparse_mat = dense_mat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 288\n",
    "time_lags = np.array([1, 2, 3, 288, 289, 290, 7 * 288, 7 * 288 + 1, 7 * 288 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on London Movement Speed Data\n",
    "\n",
    "London movement speed data set is is a city-wide hourly traffic speeddataset collected in London.\n",
    "\n",
    "- Collected from 200,000+ road segments.\n",
    "- 720 time points in April 2019.\n",
    "- 73% missing values in the original data.\n",
    "\n",
    "|  Observation rate | $>90\\%$ | $>80\\%$ | $>70\\%$ | $>60\\%$ | $>50\\%$ |\n",
    "|:------------------|--------:|--------:|--------:|--------:|--------:|\n",
    "|**Number of roads**|  17,666 |  27,148 |  35,912 |  44,352 |  52,727 |\n",
    "\n",
    "\n",
    "If want to test on the full dataset, you could consider the following setting for masking observations as missing values. \n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "mask_rate = 0.20\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "pos_obs = np.where(dense_mat != 0)\n",
    "num = len(pos_obs[0])\n",
    "sample_ind = np.random.choice(num, size = int(mask_rate * num), replace = False)\n",
    "sparse_mat = dense_mat.copy()\n",
    "sparse_mat[pos_obs[0][sample_ind], pos_obs[1][sample_ind]] = 0\n",
    "```\n",
    "\n",
    "Notably, you could also consider to evaluate the model on a subset of the data with the following setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_mat = np.zeros(dense_mat.shape)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], 30)\n",
    "for i1 in range(dense_mat.shape[0]):\n",
    "    for i2 in range(30):\n",
    "        binary_mat[i1, i2 * 24 : (i2 + 1) * 24] = np.round(random_mat[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_mat = dense_mat * binary_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 20\n",
    "- Time lags: {1, 2, 24}\n",
    "- The number of iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 24\n",
    "time_lags = np.array([1, 2, 3, 24, 25, 26, 7 * 24, 7 * 24 + 1, 7 * 24 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Random missing (RM)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], dense_mat.shape[1])\n",
    "binary_mat = np.round(random_mat + 0.5 - missing_rate)\n",
    "sparse_mat = dense_mat * binary_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 20\n",
    "- Time lags: {1, 2, 24}\n",
    "- The number of iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 24\n",
    "time_lags = np.array([1, 2, 3, 24, 25, 26, 7 * 24, 7 * 24 + 1, 7 * 24 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.6\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Random missing (RM)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], dense_mat.shape[1])\n",
    "binary_mat = np.round(random_mat + 0.5 - missing_rate)\n",
    "sparse_mat = dense_mat * binary_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 20\n",
    "- Time lags: {1, 2, 24}\n",
    "- The number of iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 24\n",
    "time_lags = np.array([1, 2, 3, 24, 25, 26, 7 * 24, 7 * 24 + 1, 7 * 24 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "sparse_mat = dense_mat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "rank = 10\n",
    "pred_step = 7 * 24\n",
    "time_lags = np.array([1, 2, 3, 24, 25, 26, 7 * 24, 7 * 24 + 1, 7 * 24 + 2])\n",
    "lambda_w = 500\n",
    "lambda_x = 500\n",
    "lambda_theta = 500\n",
    "eta = 1\n",
    "init_hyper = {\"lambda_w\": lambda_w, \"lambda_x\": lambda_x, \"lambda_theta\": lambda_theta, \"eta\": eta}\n",
    "maxiter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = TRMF_forecast(dense_mat, sparse_mat, init_hyper, pred_step, multi_step, rank, time_lags, maxiter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>This work is released under the MIT license.</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
