{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Temporal Regularized Matrix Factorization\n",
    "\n",
    "**Published**: December 17, 2020\n",
    "\n",
    "**Revised**: December 22, 2020\n",
    "\n",
    "**Author**: Xinyu Chen [[**GitHub homepage**](https://github.com/xinychen)]\n",
    "\n",
    "**Download**: This Jupyter notebook is at our GitHub repository. If you want to evaluate the code, please download the notebook from the [**transdim**](https://github.com/xinychen/transdim/blob/master/imputer/BTMF.ipynb) repository.\n",
    "\n",
    "This notebook shows how to implement the Bayesian treatment for Temporal Regularized Matrix Factorization (BTRMF) on some real-world data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description\n",
    "\n",
    "- Gaussian observations:\n",
    "\n",
    "$$y_{it}\\sim\\mathcal{N}\\left(\\boldsymbol{w}_{i}^{\\top}\\boldsymbol{x}_{t},\\tau_{i}^{-1}\\right),\\forall (i,t)\\in\\Omega$$\n",
    "\n",
    "- Prior distributions of factor matrices:\n",
    "\n",
    "$$\\boldsymbol{w}_{i}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{w},\\Lambda_{w}^{-1}\\right)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\boldsymbol{x}_{t}\\sim\\left\\{\\begin{array}{ll}\\mathcal{N}\\left(\\boldsymbol{0},\\Lambda_{x}^{-1}\\right), & \\text{if $t\\in\\{1,2,\\ldots,h_d\\}$,} \\\\ \\mathcal{N}\\left(\\sum_{k=1}^{d}\\text{diag}(\\boldsymbol{\\theta}_{k})\\boldsymbol{x}_{t-h_k},\\Lambda_{x}^{-1}\\right),& \\text{otherwise}.\\end{array}\\right.$$\n",
    "\n",
    "- Conjugate priors:\n",
    "\n",
    "$$\\boldsymbol{\\mu}_{w}\\mid\\Lambda_{w}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{0},\\left(\\beta_0\\Lambda_{w}\\right)^{-1}\\right),\\Lambda_{w}\\sim\\mathcal{W}\\left(W_0,\\nu_0\\right)$$\n",
    "\n",
    "$$\\boldsymbol{\\theta}_{k}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{\\theta},\\Lambda_{\\theta}^{-1}\\right),\\boldsymbol{\\mu}_{\\theta}\\mid\\Lambda_{\\theta}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{0},\\left(\\beta_0\\Lambda_{\\theta}\\right)^{-1}\\right),\\Lambda_{\\theta}\\sim\\mathcal{W}\\left(W_0,\\nu_0\\right)$$\n",
    "\n",
    "$$\\Lambda_{x}\\sim\\mathcal{W}\\left(W_0,\\nu_0\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv as inv\n",
    "from numpy.random import normal as normrnd\n",
    "from scipy.linalg import khatri_rao as kr_prod\n",
    "from scipy.stats import wishart\n",
    "from numpy.linalg import solve as solve\n",
    "from scipy.linalg import cholesky as cholesky_upper\n",
    "from scipy.linalg import solve_triangular as solve_ut\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvnrnd_pre(mu, Lambda):\n",
    "    src = normrnd(size = (mu.shape[0],))\n",
    "    return solve_ut(cholesky_upper(Lambda, overwrite_a = True, check_finite = False), \n",
    "                    src, lower = False, check_finite = False, overwrite_b = True) + mu\n",
    "\n",
    "def cov_mat(mat, mat_bar):\n",
    "    mat = mat - mat_bar\n",
    "    return mat.T @ mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_factor_w(tau_sparse_mat, tau_ind, W, X, tau, beta0 = 1, vargin = 0):\n",
    "    \"\"\"Sampling N-by-R factor matrix W and its hyperparameters (mu_w, Lambda_w).\"\"\"\n",
    "    \n",
    "    dim1, rank = W.shape\n",
    "    W_bar = np.mean(W, axis = 0)\n",
    "    temp = dim1 / (dim1 + beta0)\n",
    "    var_W_hyper = inv(np.eye(rank) + cov_mat(W, W_bar) + temp * beta0 * np.outer(W_bar, W_bar))\n",
    "    var_Lambda_hyper = wishart.rvs(df = dim1 + rank, scale = var_W_hyper)\n",
    "    var_mu_hyper = mvnrnd_pre(temp * W_bar, (dim1 + beta0) * var_Lambda_hyper)\n",
    "    \n",
    "    if dim1 * rank ** 2 > 1e+8:\n",
    "        vargin = 1\n",
    "    \n",
    "    if vargin == 0:\n",
    "        var1 = X.T\n",
    "        var2 = kr_prod(var1, var1)\n",
    "        var3 = (var2 @ tau_ind.T).reshape([rank, rank, dim1]) + var_Lambda_hyper[:, :, None]\n",
    "        var4 = var1 @ tau_sparse_mat.T + (var_Lambda_hyper @ var_mu_hyper)[:, None]\n",
    "        for i in range(dim1):\n",
    "            W[i, :] = mvnrnd_pre(solve(var3[:, :, i], var4[:, i]), var3[:, :, i])\n",
    "    elif vargin == 1:\n",
    "        for i in range(dim1):\n",
    "            pos0 = np.where(sparse_mat[i, :] != 0)\n",
    "            Xt = X[pos0[0], :]\n",
    "            var_mu = tau[i] * Xt.T @ sparse_mat[i, pos0[0]] + var_Lambda_hyper @ var_mu_hyper\n",
    "            var_Lambda = tau[i] * Xt.T @ Xt + var_Lambda_hyper\n",
    "            W[i, :] = mvnrnd_pre(solve(var_Lambda, var_mu), var_Lambda)\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_theta(X, theta, Lambda_x, time_lags, beta0 = 1):\n",
    "    \n",
    "    dim, rank = X.shape\n",
    "    d = time_lags.shape[0]\n",
    "    tmax = np.max(time_lags)\n",
    "    theta_bar = np.mean(theta, axis = 0)\n",
    "    temp = d / (d + beta0)\n",
    "    var_theta_hyper = inv(np.eye(rank) + cov_mat(theta, theta_bar) \n",
    "                          + temp * beta0 * np.outer(theta_bar, theta_bar))\n",
    "    var_Lambda_hyper = wishart.rvs(df = d + rank, scale = var_theta_hyper)\n",
    "    var_mu_hyper = mvnrnd_pre(temp * theta_bar, (d + beta0) * var_Lambda_hyper)\n",
    "    \n",
    "    for k in range(d):\n",
    "        theta0 = theta.copy()\n",
    "        theta0[k, :] = 0\n",
    "        mat0 = np.zeros((dim - tmax, rank))\n",
    "        for L in range(d):\n",
    "            mat0 += X[tmax - time_lags[L] : dim - time_lags[L], :] @ np.diag(theta0[L, :])\n",
    "        varPi = X[tmax : dim, :] - mat0\n",
    "        var0 = X[tmax - time_lags[k] : dim - time_lags[k], :]\n",
    "        var = np.einsum('ij, jk, ik -> j', var0, Lambda_x, varPi)\n",
    "        var_Lambda = np.einsum('ti, tj, ij -> ij', var0, var0, Lambda_x) + var_Lambda_hyper\n",
    "        theta[k, :] = mvnrnd_pre(solve(var_Lambda, var + var_Lambda_hyper @ var_mu_hyper), var_Lambda)\n",
    "        \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Likelihood $\\boldsymbol{x}_{t}\\sim\\left\\{\\begin{array}{ll}\\mathcal{N}\\left(\\boldsymbol{0},\\Lambda_{x}^{-1}\\right), & \\text{if $t\\in\\{1,2,\\ldots,h_d\\}$,} \\\\ \\mathcal{N}\\left(\\sum_{k=1}^{d}\\text{diag}(\\boldsymbol{\\theta}_{k})\\boldsymbol{x}_{t-h_k},\\Lambda_{x}^{-1}\\right),& \\text{otherwise},\\end{array}\\right.$:\n",
    "\n",
    "$$\\ln\\mathcal{L}\\left(\\boldsymbol{x}_{1},\\ldots,\\boldsymbol{x}_{T}\\mid\\boldsymbol{\\theta}_{1},\\ldots,\\boldsymbol{\\theta}_{d},\\Lambda_{x}\\right)$$\n",
    "\n",
    "$$\\propto\\frac{T}{2}\\ln\\left|\\Lambda_{x}\\right|-\\frac{1}{2}\\text{tr}\\left(\\Lambda_{x}\\sum_{t=1}^{h_d}\\boldsymbol{x}_{t}\\boldsymbol{x}_{t}^{\\top}+\\Lambda_{x}\\sum_{t=h_d+1}^{T}\\left(\\boldsymbol{x}_{t}-\\sum_{k}\\text{diag}(\\boldsymbol{\\theta}_{k})\\boldsymbol{x}_{t-h_k}\\right)\\left(\\boldsymbol{x}_{t}-\\sum_{k}\\text{diag}(\\boldsymbol{\\theta}_{k})\\boldsymbol{x}_{t-h_k}\\right)^\\top\\right)$$\n",
    "\n",
    "- Prior distribution $\\Lambda_{x}\\sim\\mathcal{W}\\left(S_0,\\nu_0\\right)$ where $\\nu_0\\geq R$:\n",
    "\n",
    "$$\\ln p\\left(\\Lambda_x\\mid S_0,\\nu_0\\right)\\propto\\frac{1}{2}(\\nu_0-R-1)\\ln\\left|\\Lambda_{x}\\right|-\\frac{1}{2}\\text{tr}\\left(\\Lambda_{x}S_0^{-1}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_Lambda_x(X, theta, time_lags):\n",
    "    \n",
    "    dim, rank = X.shape\n",
    "    d = time_lags.shape[0]\n",
    "    tmax = np.max(time_lags)\n",
    "    mat = X[: tmax, :].T @ X[: tmax, :]\n",
    "    temp = np.zeros((dim - tmax, rank, d))\n",
    "    for k in range(d):\n",
    "        temp[:, :, k] = X[tmax - time_lags[k] : dim - time_lags[k], :]\n",
    "    new_mat = X[tmax : dim, :] - np.einsum('kr, irk -> ir', theta, temp)\n",
    "    Lambda_x = wishart.rvs(df = dim + rank, scale = inv(np.eye(rank) + mat + new_mat.T @ new_mat))\n",
    "    \n",
    "    return Lambda_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_factor_x(tau_sparse_mat, tau_ind, time_lags, W, X, theta, Lambda_x):\n",
    "    \"\"\"Sampling T-by-R factor matrix X.\"\"\"\n",
    "\n",
    "    dim2, rank = X.shape\n",
    "    tmax = np.max(time_lags)\n",
    "    tmin = np.min(time_lags)\n",
    "    d = time_lags.shape[0]\n",
    "    A = np.zeros((d * rank, rank))\n",
    "    for k in range(d):\n",
    "        A[k * rank : (k + 1) * rank, :] = np.diag(theta[k, :])\n",
    "    A0 = np.dstack([A] * d)\n",
    "    for k in range(d):\n",
    "        A0[k * rank : (k + 1) * rank, :, k] = 0\n",
    "    mat0 = Lambda_x @ A.T\n",
    "    mat1 = np.einsum('kij, jt -> kit', A.reshape([d, rank, rank]), Lambda_x)\n",
    "    mat2 = np.einsum('kit, kjt -> ij', mat1, A.reshape([d, rank, rank]))\n",
    "    \n",
    "    var1 = W.T\n",
    "    var2 = kr_prod(var1, var1)\n",
    "    var3 = (var2 @ tau_ind).reshape([rank, rank, dim2]) + Lambda_x[:, :, None]\n",
    "    var4 = var1 @ tau_sparse_mat\n",
    "    for t in range(dim2):\n",
    "        Mt = np.zeros((rank, rank))\n",
    "        Nt = np.zeros(rank)\n",
    "        Qt = mat0 @ X[t - time_lags, :].reshape(rank * d)\n",
    "        index = list(range(0, d))\n",
    "        if t >= dim2 - tmax and t < dim2 - tmin:\n",
    "            index = list(np.where(t + time_lags < dim2))[0]\n",
    "        elif t < tmax:\n",
    "            Qt = np.zeros(rank)\n",
    "            index = list(np.where(t + time_lags >= tmax))[0]\n",
    "        if t < dim2 - tmin:\n",
    "            Mt = mat2.copy()\n",
    "            temp = np.zeros((rank * d, len(index)))\n",
    "            n = 0\n",
    "            for k in index:\n",
    "                temp[:, n] = X[t + time_lags[k] - time_lags, :].reshape(rank * d)\n",
    "                n += 1\n",
    "            temp0 = X[t + time_lags[index], :].T - np.einsum('ijk, ik -> jk', A0[:, :, index], temp)\n",
    "            Nt = np.einsum('kij, jk -> i', mat1[index, :, :], temp0)\n",
    "        \n",
    "        var3[:, :, t] = var3[:, :, t] + Mt\n",
    "        if t < tmax:\n",
    "            var3[:, :, t] = var3[:, :, t] - Lambda_x + np.eye(rank)\n",
    "        X[t, :] = mvnrnd_pre(solve(var3[:, :, t], var4[:, t] + Nt + Qt), var3[:, :, t])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_precision_tau(sparse_mat, mat_hat, ind):\n",
    "    var_alpha = 1e-6 + 0.5 * np.sum(ind, axis = 1)\n",
    "    var_beta = 1e-6 + 0.5 * np.sum(((sparse_mat - mat_hat) ** 2) * ind, axis = 1)\n",
    "    return np.random.gamma(var_alpha, 1 / var_beta)\n",
    "\n",
    "def sample_precision_scalar_tau(sparse_mat, mat_hat, ind):\n",
    "    var_alpha = 1e-6 + 0.5 * np.sum(ind)\n",
    "    var_beta = 1e-6 + 0.5 * np.sum(((sparse_mat - mat_hat) ** 2) * ind)\n",
    "    return np.random.gamma(var_alpha, 1 / var_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return  np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BTRMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter, option = \"factor\"):\n",
    "    \"\"\"Bayesian Temporal Regularized Matrix Factorization, BTRMF.\"\"\"\n",
    "    \n",
    "    dim1, dim2 = sparse_mat.shape\n",
    "    d = time_lags.shape[0]\n",
    "    W = init[\"W\"]\n",
    "    X = init[\"X\"]\n",
    "    theta = 0.01 * np.random.randn(d, rank)\n",
    "    if np.isnan(sparse_mat).any() == False:\n",
    "        ind = sparse_mat != 0\n",
    "        pos_obs = np.where(ind)\n",
    "        pos_test = np.where((dense_mat != 0) & (sparse_mat == 0))\n",
    "    elif np.isnan(sparse_mat).any() == True:\n",
    "        pos_test = np.where((dense_mat != 0) & (np.isnan(sparse_mat)))\n",
    "        ind = ~np.isnan(sparse_mat)\n",
    "        pos_obs = np.where(ind)\n",
    "        sparse_mat[np.isnan(sparse_mat)] = 0\n",
    "    dense_test = dense_mat[pos_test]\n",
    "    del dense_mat\n",
    "    ind = sparse_mat != 0\n",
    "    tau = np.ones(dim1)\n",
    "    W_plus = np.zeros((dim1, rank))\n",
    "    X_plus = np.zeros((dim2, rank))\n",
    "    theta_plus = np.zeros((d, rank))\n",
    "    temp_hat = np.zeros(len(pos_test[0]))\n",
    "    show_iter = 200\n",
    "    mat_hat_plus = np.zeros((dim1, dim2))\n",
    "    for it in range(burn_iter + gibbs_iter):\n",
    "        tau_ind = tau[:, None] * ind\n",
    "        tau_sparse_mat = tau[:, None] * sparse_mat\n",
    "        W = sample_factor_w(tau_sparse_mat, tau_ind, W, X, tau, beta0 = 1, vargin = 0)\n",
    "        Lambda_x = sample_Lambda_x(X, theta, time_lags)\n",
    "        theta = sample_theta(X, theta, Lambda_x, time_lags)\n",
    "        X = sample_factor_x(tau_sparse_mat, tau_ind, time_lags, W, X, theta, Lambda_x)\n",
    "        mat_hat = W @ X.T\n",
    "        if option == \"factor\":\n",
    "            tau = sample_precision_tau(sparse_mat, mat_hat, ind)\n",
    "        elif option == \"pca\":\n",
    "            tau = sample_precision_scalar_tau(sparse_mat, mat_hat, ind)\n",
    "            tau = tau * np.ones(dim1)\n",
    "        temp_hat += mat_hat[pos_test]\n",
    "        if (it + 1) % show_iter == 0 and it < burn_iter:\n",
    "            temp_hat = temp_hat / show_iter\n",
    "            print('Iter: {}'.format(it + 1))\n",
    "            print('MAPE: {:.6}'.format(compute_mape(dense_test, temp_hat)))\n",
    "            print('RMSE: {:.6}'.format(compute_rmse(dense_test, temp_hat)))\n",
    "            temp_hat = np.zeros(len(pos_test[0]))\n",
    "            print()\n",
    "        if it + 1 > burn_iter:\n",
    "            W_plus += W\n",
    "            X_plus += X\n",
    "            theta_plus += theta\n",
    "            mat_hat_plus += mat_hat\n",
    "    mat_hat = mat_hat_plus / gibbs_iter\n",
    "    W = W_plus / gibbs_iter\n",
    "    X = X_plus / gibbs_iter\n",
    "    theta = theta_plus / gibbs_iter\n",
    "    print('Imputation MAPE: {:.6}'.format(compute_mape(dense_test, mat_hat[:, : dim2][pos_test])))\n",
    "    print('Imputation RMSE: {:.6}'.format(compute_rmse(dense_test, mat_hat[:, : dim2][pos_test])))\n",
    "    print()\n",
    "    mat_hat[mat_hat < 0] = 0\n",
    "    \n",
    "    return mat_hat, W, X, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Guangzhou Speed Data\n",
    "\n",
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $214\\times 61\\times 144$ (road segment, day, time of day)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "dim = dense_tensor.shape\n",
    "missing_rate = 0.4 # Non-random missing (NM)\n",
    "sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1])[:, :, np.newaxis] + 0.5 - missing_rate)\n",
    "dense_mat = dense_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "sparse_mat = sparse_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "del dense_tensor, sparse_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Time lags: {1, 2, 144}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.102392\n",
      "RMSE: 4.32927\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.102399\n",
      "RMSE: 4.34368\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.102638\n",
      "RMSE: 4.35184\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.102881\n",
      "RMSE: 4.36252\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.102905\n",
      "RMSE: 4.36489\n",
      "\n",
      "Imputation MAPE: 0.103105\n",
      "Imputation RMSE: 4.37774\n",
      "\n",
      "Running time: 1204 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 144])\n",
    "init = {\"W\": 0.01 * np.random.randn(dim1, rank), \"X\": 0.01 * np.random.randn(dim2, rank)}\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "mat_hat, W, X, theta = BTRMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $214\\times 61\\times 144$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "dim = dense_tensor.shape\n",
    "missing_rate = 0.4 # Random missing (RM)\n",
    "sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "dense_mat = dense_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "sparse_mat = sparse_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "del dense_tensor, sparse_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 80\n",
    "- Time lags: {1, 2, 144}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.07524\n",
      "RMSE: 3.23358\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0750662\n",
      "RMSE: 3.23704\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0751602\n",
      "RMSE: 3.24055\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0751735\n",
      "RMSE: 3.24014\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0751397\n",
      "RMSE: 3.2408\n",
      "\n",
      "Imputation MAPE: 0.0751391\n",
      "Imputation RMSE: 3.24151\n",
      "\n",
      "Running time: 8652 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 80\n",
    "time_lags = np.array([1, 2, 144])\n",
    "init = {\"W\": 0.1 * np.random.randn(dim1, rank), \"X\": 0.1 * np.random.randn(dim2, rank)}\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "mat_hat, W, X, theta = BTRMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $214\\times 61\\times 144$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 60% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "dim = dense_tensor.shape\n",
    "missing_rate = 0.6 # Random missing (RM)\n",
    "sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "dense_mat = dense_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "sparse_mat = sparse_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "del dense_tensor, sparse_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 80\n",
    "- Time lags: {1, 2, 144}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0792675\n",
      "RMSE: 3.39314\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0788858\n",
      "RMSE: 3.39416\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0791253\n",
      "RMSE: 3.40214\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0792649\n",
      "RMSE: 3.40805\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0793919\n",
      "RMSE: 3.41317\n",
      "\n",
      "Imputation MAPE: 0.0794925\n",
      "Imputation RMSE: 3.4151\n",
      "\n",
      "Running time: 8388 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 80\n",
    "time_lags = np.array([1, 2, 144])\n",
    "init = {\"W\": 0.1 * np.random.randn(dim1, rank), \"X\": 0.1 * np.random.randn(dim2, rank)}\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "mat_hat, W, X, theta = BTRMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Hangzhou Flow Data\n",
    "\n",
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $80\\times 25\\times 108$ (metro station, day, time of day)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')['tensor']\n",
    "dim = dense_tensor.shape\n",
    "missing_rate = 0.4 # Non-random missing (NM)\n",
    "sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1])[:, :, np.newaxis] + 0.5 - missing_rate)\n",
    "dense_mat = dense_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "sparse_mat = sparse_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "del dense_tensor, sparse_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 30\n",
    "- Time lags: {1, 2, 108}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.256171\n",
      "RMSE: 54.7371\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.268451\n",
      "RMSE: 55.1768\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.266337\n",
      "RMSE: 53.5283\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.266646\n",
      "RMSE: 52.6491\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.280712\n",
      "RMSE: 51.4976\n",
      "\n",
      "Imputation MAPE: 0.270754\n",
      "Imputation RMSE: 51.7259\n",
      "\n",
      "Running time: 672 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 30\n",
    "time_lags = np.array([1, 2, 108])\n",
    "init = {\"W\": 0.01 * np.random.randn(dim1, rank), \"X\": 0.01 * np.random.randn(dim2, rank)}\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "mat_hat, W, X, theta = BTRMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter, option = \"pca\")\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $80\\times 25\\times 108$ (metro station, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')['tensor']\n",
    "dim = dense_tensor.shape\n",
    "missing_rate = 0.4 # Random missing (RM)\n",
    "sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "dense_mat = dense_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "sparse_mat = sparse_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "del dense_tensor, sparse_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 30\n",
    "- Time lags: {1, 2, 108}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.224843\n",
      "RMSE: 35.1102\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.228051\n",
      "RMSE: 33.545\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.226576\n",
      "RMSE: 33.4804\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.229436\n",
      "RMSE: 33.5221\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.22548\n",
      "RMSE: 33.4536\n",
      "\n",
      "Imputation MAPE: 0.226545\n",
      "Imputation RMSE: 33.4711\n",
      "\n",
      "Running time: 602 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 30\n",
    "time_lags = np.array([1, 2, 108])\n",
    "init = {\"W\": 0.1 * np.random.randn(dim1, rank), \"X\": 0.1 * np.random.randn(dim2, rank)}\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "mat_hat, W, X, theta = BTRMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter, option = \"pca\")\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $80\\times 25\\times 108$ (metro station, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 60% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')['tensor']\n",
    "dim = dense_tensor.shape\n",
    "missing_rate = 0.6 # Random missing (RM)\n",
    "sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "dense_mat = dense_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "sparse_mat = sparse_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "del dense_tensor, sparse_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 30\n",
    "- Time lags: {1, 2, 108}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.239444\n",
      "RMSE: 49.6641\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.24268\n",
      "RMSE: 42.9047\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.245536\n",
      "RMSE: 39.5845\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.244401\n",
      "RMSE: 38.0904\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.246259\n",
      "RMSE: 37.1305\n",
      "\n",
      "Imputation MAPE: 0.24692\n",
      "Imputation RMSE: 37.0711\n",
      "\n",
      "Running time: 753 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 30\n",
    "time_lags = np.array([1, 2, 108])\n",
    "init = {\"W\": 0.1 * np.random.randn(dim1, rank), \"X\": 0.1 * np.random.randn(dim2, rank)}\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "mat_hat, W, X, theta = BTRMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter, option = \"pca\")\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Seattle Speed Data\n",
    "\n",
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $323\\times 28\\times 288$ (road segment, day, time of day)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Seattle-data-set/tensor.npz')['arr_0']\n",
    "dim = dense_tensor.shape\n",
    "missing_rate = 0.4 # Non-random missing (NM)\n",
    "sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1])[:, :, np.newaxis] + 0.5 - missing_rate)\n",
    "dense_mat = dense_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "sparse_mat = sparse_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "del dense_tensor, sparse_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Time lags: {1, 2, 288}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0938158\n",
      "RMSE: 5.38035\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0930455\n",
      "RMSE: 5.36452\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0933777\n",
      "RMSE: 5.38176\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0934608\n",
      "RMSE: 5.38578\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0934591\n",
      "RMSE: 5.38655\n",
      "\n",
      "Imputation MAPE: 0.0932756\n",
      "Imputation RMSE: 5.37778\n",
      "\n",
      "Running time: 1093 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 10\n",
    "time_lags = np.array([1, 2, 288])\n",
    "init = {\"W\": 0.01 * np.random.randn(dim1, rank), \"X\": 0.01 * np.random.randn(dim2, rank)}\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "mat_hat, W, X, theta = BTRMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $323\\times 28\\times 288$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Seattle-data-set/tensor.npz')['arr_0']\n",
    "dim = dense_tensor.shape\n",
    "missing_rate = 0.4 # Random missing (RM)\n",
    "sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "dense_mat = dense_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "sparse_mat = sparse_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "del dense_tensor, sparse_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 50\n",
    "- Time lags: {1, 2, 288}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0596038\n",
      "RMSE: 3.74737\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0595248\n",
      "RMSE: 3.75127\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0595014\n",
      "RMSE: 3.7492\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.059484\n",
      "RMSE: 3.74841\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0594566\n",
      "RMSE: 3.74681\n",
      "\n",
      "Imputation MAPE: 0.0594566\n",
      "Imputation RMSE: 3.74573\n",
      "\n",
      "Running time: 3780 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 50\n",
    "time_lags = np.array([1, 2, 288])\n",
    "init = {\"W\": 0.1 * np.random.randn(dim1, rank), \"X\": 0.1 * np.random.randn(dim2, rank)}\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "mat_hat, W, X, theta = BTRMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $323\\times 28\\times 288$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 60% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "dense_tensor = scipy.io.loadmat('../datasets/Seattle-data-set/tensor.npz')['arr_0']\n",
    "dim = dense_tensor.shape\n",
    "missing_rate = 0.6 # Random missing (RM)\n",
    "sparse_tensor = dense_tensor * np.round(np.random.rand(dim[0], dim[1], dim[2]) + 0.5 - missing_rate)\n",
    "dense_mat = dense_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "sparse_mat = sparse_tensor.reshape([dim[0], dim[1] * dim[2]])\n",
    "del dense_tensor, sparse_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 50\n",
    "- Time lags: {1, 2, 288}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0614937\n",
      "RMSE: 3.8319\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0613195\n",
      "RMSE: 3.83203\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0612728\n",
      "RMSE: 3.83117\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0613037\n",
      "RMSE: 3.83298\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0613246\n",
      "RMSE: 3.83193\n",
      "\n",
      "Imputation MAPE: 0.0612939\n",
      "Imputation RMSE: 3.8312\n",
      "\n",
      "Running time: 3794 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 50\n",
    "time_lags = np.array([1, 2, 288])\n",
    "init = {\"W\": 0.1 * np.random.randn(dim1, rank), \"X\": 0.1 * np.random.randn(dim2, rank)}\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "mat_hat, W, X, theta = BTRMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on London Movement Speed Data\n",
    "\n",
    "London movement speed data set is is a city-wide hourly traffic speeddataset collected in London.\n",
    "\n",
    "- Collected from 200,000+ road segments.\n",
    "- 720 time points in April 2019.\n",
    "- 73% missing values in the original data.\n",
    "\n",
    "|  Observation rate | $>90\\%$ | $>80\\%$ | $>70\\%$ | $>60\\%$ | $>50\\%$ |\n",
    "|:------------------|--------:|--------:|--------:|--------:|--------:|\n",
    "|**Number of roads**|  17,666 |  27,148 |  35,912 |  44,352 |  52,727 |\n",
    "\n",
    "\n",
    "If want to test on the full dataset, you could consider the following setting for masking observations as missing values. \n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "mask_rate = 0.20\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "pos_obs = np.where(dense_mat != 0)\n",
    "num = len(pos_obs[0])\n",
    "sample_ind = np.random.choice(num, size = int(mask_rate * num), replace = False)\n",
    "sparse_mat = dense_mat.copy()\n",
    "sparse_mat[pos_obs[0][sample_ind], pos_obs[1][sample_ind]] = 0\n",
    "```\n",
    "\n",
    "Notably, you could also consider to evaluate the model on a subset of the data with the following setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_mat = np.zeros(dense_mat.shape)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], 30)\n",
    "for i1 in range(dense_mat.shape[0]):\n",
    "    for i2 in range(30):\n",
    "        binary_mat[i1, i2 * 24 : (i2 + 1) * 24] = np.round(random_mat[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_mat = dense_mat * binary_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 20\n",
    "- Time lags: {1, 2, 24}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0948059\n",
      "RMSE: 2.34777\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0942527\n",
      "RMSE: 2.3214\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0942426\n",
      "RMSE: 2.32111\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0942407\n",
      "RMSE: 2.32104\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0942403\n",
      "RMSE: 2.321\n",
      "\n",
      "Imputation MAPE: 0.0942378\n",
      "Imputation RMSE: 2.32091\n",
      "\n",
      "Running time: 3394 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 20\n",
    "time_lags = np.array([1, 2, 24])\n",
    "init = {\"W\": 0.01 * np.random.randn(dim1, rank), \"X\": 0.01 * np.random.randn(dim2, rank)}\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "mat_hat, W, X, theta = BTRMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Random missing (RM)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], dense_mat.shape[1])\n",
    "binary_mat = np.round(random_mat + 0.5 - missing_rate)\n",
    "sparse_mat = dense_mat * binary_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 20\n",
    "- Time lags: {1, 2, 24}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0921362\n",
      "RMSE: 2.28467\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0914762\n",
      "RMSE: 2.25792\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0914818\n",
      "RMSE: 2.25793\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0914829\n",
      "RMSE: 2.25798\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0914881\n",
      "RMSE: 2.25802\n",
      "\n",
      "Imputation MAPE: 0.0914868\n",
      "Imputation RMSE: 2.25799\n",
      "\n",
      "Running time: 3542 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 20\n",
    "time_lags = np.array([1, 2, 24])\n",
    "init = {\"W\": 0.01 * np.random.randn(dim1, rank), \"X\": 0.01 * np.random.randn(dim2, rank)}\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "mat_hat, W, X, theta = BTRMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.6\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Random missing (RM)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], dense_mat.shape[1])\n",
    "binary_mat = np.round(random_mat + 0.5 - missing_rate)\n",
    "sparse_mat = dense_mat * binary_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 20\n",
    "- Time lags: {1, 2, 24}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 200\n",
      "MAPE: 0.0942398\n",
      "RMSE: 2.33817\n",
      "\n",
      "Iter: 400\n",
      "MAPE: 0.0931625\n",
      "RMSE: 2.29652\n",
      "\n",
      "Iter: 600\n",
      "MAPE: 0.0931634\n",
      "RMSE: 2.29655\n",
      "\n",
      "Iter: 800\n",
      "MAPE: 0.0931634\n",
      "RMSE: 2.29658\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.093168\n",
      "RMSE: 2.29656\n",
      "\n",
      "Imputation MAPE: 0.0931706\n",
      "Imputation RMSE: 2.29665\n",
      "\n",
      "Running time: 3692 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "dim1, dim2 = sparse_mat.shape\n",
    "rank = 20\n",
    "time_lags = np.array([1, 2, 24])\n",
    "init = {\"W\": 0.01 * np.random.randn(dim1, rank), \"X\": 0.01 * np.random.randn(dim2, rank)}\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "mat_hat, W, X, theta = BTRMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter)\n",
    "end = time.time()\n",
    "print('Running time: %d seconds'%(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>This work is released under the MIT license.</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
