{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-Tubal-Rank Smoothing Tensor Completion Imputer (LSTC-Tubal)\n",
    "\n",
    "This notebook shows how to implement a LSTC-Tubal imputer on some real-world large-scale data sets. To overcome the problem of missing values within multivariate time series data, this method takes into account both low-rank structure and time series regression. Meanwhile, to make the model scalable, we also integrate linear transform into the LATC model. For an in-depth discussion of LATC-Tubal-imputer, please see [1].\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=\"black\">\n",
    "<b>[1]</b> Xinyu Chen, Yixian Chen, Lijun Sun (2020). <b>Scalable low-rank tensor learning for spatiotemporal traffic data imputation</b>. arXiv: 2008.03194. <a href=\"https://arxiv.org/abs/2008.03194\" title=\"PDF\"><b>[PDF]</b></a> <a href=\"https://doi.org/10.5281/zenodo.3939792\" title=\"data\"><b>[data]</b></a> \n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LATC-imputer kernel\n",
    "\n",
    "We start by introducing some necessary functions that relies on `Numpy`.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<ul>\n",
    "<li><b><code>ten2mat</code>:</b> <font color=\"black\">Unfold tensor as matrix by specifying mode.</font></li>\n",
    "<li><b><code>mat2ten</code>:</b> <font color=\"black\">Fold matrix as tensor by specifying dimension (i.e, tensor size) and mode.</font></li>\n",
    "<li><b><code>svt</code>:</b> <font color=\"black\">Implement the process of Singular Value Thresholding (SVT).</font></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:58:07.897301Z",
     "start_time": "2021-01-16T15:58:07.733271Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')\n",
    "\n",
    "def mat2ten(mat, dim, mode):\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(dim.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, list(dim[index]), order = 'F'), 0, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:58:08.944918Z",
     "start_time": "2021-01-16T15:58:08.925922Z"
    }
   },
   "outputs": [],
   "source": [
    "def unitary_transform(tensor, Phi):\n",
    "    return np.einsum('kt, ijk -> ijt', Phi, tensor)\n",
    "\n",
    "def inv_unitary_transform(tensor, Phi):\n",
    "    return np.einsum('kt, ijt -> ijk', Phi, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:58:10.206083Z",
     "start_time": "2021-01-16T15:58:10.132086Z"
    }
   },
   "outputs": [],
   "source": [
    "def tsvt_unitary(tensor, Phi, tau):\n",
    "    dim = tensor.shape\n",
    "    X = np.zeros(dim)\n",
    "    tensor = unitary_transform(tensor, Phi)\n",
    "    for t in range(dim[2]):\n",
    "        u, s, v = np.linalg.svd(tensor[:, :, t], full_matrices = False)\n",
    "        r = len(np.where(s > tau)[0])\n",
    "        if r >= 1:\n",
    "            s = s[: r]\n",
    "            s[: r] = s[: r] - tau\n",
    "            X[:, :, t] = u[:, : r] @ np.diag(s) @ v[: r, :]\n",
    "    return inv_unitary_transform(X, Phi)\n",
    "\n",
    "from scipy.fftpack import dctn, idctn\n",
    "\n",
    "def tsvt_dct(tensor, tau):\n",
    "    dim = tensor.shape\n",
    "    X = np.zeros(dim)\n",
    "    tensor = dctn(tensor, axes = (2,), norm = 'ortho')\n",
    "    for t in range(dim[2]):\n",
    "        u, s, v = np.linalg.svd(tensor[:, :, t], full_matrices = False)\n",
    "        r = len(np.where(s > tau)[0])\n",
    "        if r >= 1:\n",
    "            s = s[: r]\n",
    "            s[: r] = s[: r] - tau\n",
    "            X[:, :, t] = u[:, : r] @ np.diag(s) @ v[: r, :]\n",
    "    return idctn(X, axes = (2,), norm = 'ortho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<ul>\n",
    "<li><b><code>compute_mape</code>:</b> <font color=\"black\">Compute the value of Mean Absolute Percentage Error (MAPE).</font></li>\n",
    "<li><b><code>compute_rmse</code>:</b> <font color=\"black\">Compute the value of Root Mean Square Error (RMSE).</font></li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "> Note that $$\\mathrm{MAPE}=\\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\left|y_{i}-\\hat{y}_{i}\\right|}{y_{i}} \\times 100, \\quad\\mathrm{RMSE}=\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}},$$ where $n$ is the total number of estimated values, and $y_i$ and $\\hat{y}_i$ are the actual value and its estimation, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-16T15:58:11.964019Z",
     "start_time": "2021-01-16T15:58:11.943995Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return  np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea behind LATC-imputer is to approximate partially observed data with both low-rank structure and time series dynamics. The following `imputer` kernel includes some necessary inputs:\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<ul>\n",
    "<li><b><code>dense_tensor</code>:</b> <font color=\"black\">This is an input which has the ground truth for validation. If this input is not available, you could use <code>dense_tensor = sparse_tensor.copy()</code> instead.</font></li>\n",
    "<li><b><code>sparse_tensor</code>:</b> <font color=\"black\">This is a partially observed tensor which has many missing entries.</font></li>\n",
    "<li><b><code>time_lags</code>:</b> <font color=\"black\">Time lags, e.g., <code>time_lags = np.array([1, 2, 3])</code>. </font></li>\n",
    "<li><b><code>alpha</code>:</b> <font color=\"black\">Weights for tensors' nuclear norm, e.g., <code>alpha = np.ones(3) / 3</code>. </font></li>\n",
    "<li><b><code>rho</code>:</b> <font color=\"black\">Learning rate for ADMM, e.g., <code>rho = 0.0005</code>. </font></li>\n",
    "<li><b><code>lambda0</code>:</b> <font color=\"black\">Weight for time series regressor, e.g., <code>lambda0 = 5 * rho</code>. If <code>lambda0 = 0</code>, then this imputer is actually a standard low-rank tensor completion (i.e., High-accuracy Low-Rank Tensor Completion, or HaLRTC).</font></li>\n",
    "<li><b><code>epsilon</code>:</b> <font color=\"black\">Stop criteria, e.g., <code>epsilon = 0.001</code>. </font></li>\n",
    "<li><b><code>maxiter</code>:</b> <font color=\"black\">Maximum iteration to stop algorithm, e.g., <code>maxiter = 50</code>. </font></li>\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputer(dense_tensor, sparse_tensor, rho0, lambda0, epsilon, maxiter, \n",
    "            sparse_Psi = True, transform = \"unitary\"):\n",
    "    \"\"\"Low-Tubal-Rank Smoothing Tensor Completion, LSTC-Tubal-imputer.\"\"\"\n",
    "    \n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    dt = np.int(np.prod(dim) / dim[0])\n",
    "    sparse_mat = ten2mat(sparse_tensor, 0)\n",
    "    pos_missing = np.where(sparse_mat == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    var = dense_tensor[pos_test]\n",
    "    \n",
    "    T = np.zeros(dim)                         # \\boldsymbol{\\mathcal{T}}\n",
    "    Z = sparse_mat.copy()                     # \\boldsymbol{Z}\n",
    "    Z[pos_missing] = np.mean(sparse_mat[sparse_mat != 0])\n",
    "    it = 0\n",
    "    last_mat = sparse_mat.copy()\n",
    "    snorm = np.linalg.norm(sparse_mat, 'fro')\n",
    "    del dense_tensor, sparse_tensor, sparse_mat\n",
    "    rho = rho0\n",
    "    Phis = []\n",
    "    if transform == \"unitary\":\n",
    "        temp1 = ten2mat(mat2ten(Z, dim, 0), 2)\n",
    "        _, Phi = np.linalg.eig(temp1 @ temp1.T)\n",
    "        Phis.append(Phi)\n",
    "        del temp1\n",
    "    if lambda0 > 0:\n",
    "        if sparse_Psi == True:\n",
    "            from scipy import sparse\n",
    "            from scipy.sparse.linalg import inv as inv\n",
    "            Psi1 = sparse.coo_matrix((np.ones(dt - 1), (np.arange(0, dt - 1), np.arange(0, dt - 1))), \n",
    "                                     shape = (dt - 1, dt)).tocsr()\n",
    "            Psi2 = sparse.coo_matrix((np.ones(dt - 1), (np.arange(0, dt - 1), np.arange(0, dt - 1) + 1)), \n",
    "                                     shape = (dt - 1, dt)).tocsr()\n",
    "            temp0 = Psi2 - Psi1\n",
    "            temp0 = temp0.T @ temp0\n",
    "            Imat = sparse.coo_matrix((np.ones(dt), (np.arange(0, dt), np.arange(0, dt))), shape = (dt, dt)).tocsr()\n",
    "            const = rho * inv(temp0 + rho * Imat / lambda0).todense() / lambda0\n",
    "        elif sparse_Psi == False:\n",
    "            Psi1 = np.append(np.eye(dt - 1), np.zeros((dt - 1, 1)), axis = 1)\n",
    "            Psi2 = np.append(np.zeros((dt - 1, 1)), np.eye(dt - 1), axis = 1)\n",
    "            temp0 = Psi2 - Psi1\n",
    "            temp0 = temp0.T @ temp0\n",
    "            const = rho * np.linalg.inv(temp0 + rho * np.eye(dt) / lambda0) / lambda0\n",
    "        del Psi1, Psi2, temp0\n",
    "    while True:\n",
    "        rho = min(rho * 1.05, 1e5)\n",
    "        if transform == \"unitary\":\n",
    "            X = tsvt_unitary(mat2ten(Z, dim, 0) - T / rho, Phi, 1 / rho)\n",
    "        elif transform == \"dct\":\n",
    "            X = tsvt_dct(mat2ten(Z, dim, 0) - T / rho, 1 / rho)\n",
    "        mat_hat = ten2mat(X, 0)\n",
    "        temp = ten2mat(X + T / rho, 0)\n",
    "        if lambda0 > 0:\n",
    "            Z[pos_missing] = (temp @ const)[pos_missing]\n",
    "        elif lambda0 == 0:\n",
    "            Z[pos_missing] = temp[pos_missing]\n",
    "        T = T + rho * (X - mat2ten(Z, dim, 0))\n",
    "        tol = np.linalg.norm((mat_hat - last_mat), 'fro') / snorm\n",
    "        last_mat = mat_hat.copy()\n",
    "        it += 1\n",
    "        if it % 10 == 0:\n",
    "            if transform == \"unitary\":\n",
    "                temp1 = ten2mat(mat2ten(Z, dim, 0) - T / rho, 2)\n",
    "                _, Phi = np.linalg.eig(temp1 @ temp1.T)\n",
    "                Phis.append(Phi)\n",
    "                del temp1\n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            break\n",
    "\n",
    "    return X, Phis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model with Graph Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the following codes to generate graph partitioning scheme.\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pymetis\n",
    "import pandas as pd\n",
    "\n",
    "def load_graph_data(pkl_filename):\n",
    "    sensor_ids, sensor_id_to_ind, adj_mx = load_pickle(pkl_filename)\n",
    "    return sensor_ids, sensor_id_to_ind, adj_mx\n",
    "\n",
    "def load_pickle(pickle_file):\n",
    "    try:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            pickle_data = pickle.load(f)\n",
    "    except UnicodeDecodeError as e:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            pickle_data = pickle.load(f, encoding='latin1')\n",
    "    except Exception as e:\n",
    "        print('Unable to load data ', pickle_file, ':', e)\n",
    "        raise\n",
    "    return pickle_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sid, sind, adj = load_graph_data('adj_mat.pkl')\n",
    "    print(adj.shape)\n",
    "    adj_lst = []\n",
    "    part_pems = pd.DataFrame()\n",
    "    for i in range(len(adj)):\n",
    "        idx = np.setdiff1d(np.where(adj[i,:] > 0)[0], np.array([i]))\n",
    "        adj_lst.append(idx)\n",
    "    for k in [2, 4, 8, 16, 32, 64]:\n",
    "        cuts, labels = pymetis.part_graph(k, adjacency=adj_lst)\n",
    "        print(set(labels))\n",
    "        part_pems[str(k)] = labels\n",
    "    part_pems.to_csv('../datasets/California-data-set/graph_pems.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>16</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2  4  8  16  32  64\n",
       "0  0  1  2   6   5  47\n",
       "1  0  1  2   6   5  47\n",
       "2  0  1  2   6   5  47\n",
       "3  0  1  2   6   5  47\n",
       "4  0  1  2   6   5  47"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "graph_pems = pd.read_csv('../datasets/California-data-set/graph_pems.csv')\n",
    "graph_pems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph partitioning: 2.\n",
      "Final MAPE:\n",
      "[[0.01738425 0.0174949  0.01853146 0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Final RMSE:\n",
      "[[1.61571587 1.6242425  1.71080927 0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Final MAPE:\n",
      "[[0.01738425 0.0174949  0.01853146 0.        ]\n",
      " [0.01729041 0.01732774 0.01784786 0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Final RMSE:\n",
      "[[1.61571587 1.6242425  1.71080927 0.        ]\n",
      " [1.61231931 1.61608982 1.66216485 0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Final MAPE:\n",
      "[[0.01738425 0.0174949  0.01853146 0.        ]\n",
      " [0.01729041 0.01732774 0.01784786 0.        ]\n",
      " [0.01991922 0.01917813 0.01805003 0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "Final RMSE:\n",
      "[[1.61571587 1.6242425  1.71080927 0.        ]\n",
      " [1.61231931 1.61608982 1.66216485 0.        ]\n",
      " [1.75867292 1.71546107 1.66014643 0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "\n",
      "Graph partitioning: 4.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-4w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 4 * 7]), 0)\n",
    "random_tensor = np.random.rand(data.values.shape[0], 288, 4 * 7)\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "### Random missing (RM)\n",
    "sparse_tensor = dense_tensor * np.round(random_tensor + 0.5 - missing_rate)\n",
    "del data, random_tensor\n",
    "\n",
    "## Test LSTC-Tubal Model\n",
    "epsilon = 1e-3\n",
    "maxiter = 100\n",
    "pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "var = dense_tensor[pos_test]\n",
    "mape = np.zeros((7, 3, 3))\n",
    "rmse = np.zeros((7, 3, 3))\n",
    "\n",
    "for i in range(1, 7):\n",
    "    print('Graph partitioning: {}.'.format(2 ** i))\n",
    "    j = 0\n",
    "    for rho in [1e-3, 5e-3, 1e-2]:\n",
    "        k = 0\n",
    "        for c in [1e-3, 1e-2, 1e-1]:\n",
    "            lambda0 = c * rho\n",
    "            tensor_hat = np.zeros(dense_tensor.shape)\n",
    "            if i == 0:\n",
    "                tensor_hat, _ = imputer(dense_tensor, sparse_tensor, rho, lambda0, epsilon, maxiter)\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            else:\n",
    "                road = graph_pems.values[:, i - 1]\n",
    "                for d in range(2 ** i):\n",
    "                    pos = np.where(road == d)\n",
    "                    dense = dense_tensor[pos[0], :, :]\n",
    "                    sparse = sparse_tensor[pos[0], :, :]\n",
    "                    small_tensor, _ = imputer(dense, sparse, rho, lambda0, epsilon, maxiter)\n",
    "                    tensor_hat[pos[0], :, :] = small_tensor\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            k += 1\n",
    "        j += 1\n",
    "        print('Final MAPE:')\n",
    "        print(mape[i, :, :])\n",
    "        print('Final RMSE:')\n",
    "        print(rmse[i, :, :])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-4w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 4 * 7]), 0)\n",
    "random_tensor = np.random.rand(data.values.shape[0], 288, 4 * 7)\n",
    "\n",
    "missing_rate = 0.7\n",
    "\n",
    "### Random missing (RM)\n",
    "sparse_tensor = dense_tensor * np.round(random_tensor + 0.5 - missing_rate)\n",
    "del data, random_tensor\n",
    "\n",
    "## Test LSTC-Tubal Model\n",
    "epsilon = 1e-3\n",
    "maxiter = 100\n",
    "pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "var = dense_tensor[pos_test]\n",
    "mape = np.zeros((7, 3, 3))\n",
    "rmse = np.zeros((7, 3, 3))\n",
    "\n",
    "for i in range(1, 7):\n",
    "    print('Graph partitioning: {}.'.format(2 ** i))\n",
    "    j = 0\n",
    "    for rho in [1e-3, 5e-3, 1e-2]:\n",
    "        k = 0\n",
    "        for c in [1e-3, 1e-2, 1e-1]:\n",
    "            lambda0 = c * rho\n",
    "            tensor_hat = np.zeros(dense_tensor.shape)\n",
    "            if i == 0:\n",
    "                tensor_hat, _ = imputer(dense_tensor, sparse_tensor, rho, lambda0, epsilon, maxiter)\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            else:\n",
    "                road = graph_pems.values[:, i - 1]\n",
    "                for d in range(2 ** i):\n",
    "                    pos = np.where(road == d)\n",
    "                    dense = dense_tensor[pos[0], :, :]\n",
    "                    sparse = sparse_tensor[pos[0], :, :]\n",
    "                    small_tensor, _ = imputer(dense, sparse, rho, lambda0, epsilon, maxiter)\n",
    "                    tensor_hat[pos[0], :, :] = small_tensor\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            k += 1\n",
    "        j += 1\n",
    "        print('Final MAPE:')\n",
    "        print(mape[i, :, :])\n",
    "        print('Final RMSE:')\n",
    "        print(rmse[i, :, :])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-4w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 4 * 7]), 0)\n",
    "random_matrix = np.random.rand(data.values.shape[0], 4 * 7)\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "### Non-random missing (NM) scenario:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[2]):\n",
    "        binary_tensor[i1, :, i2] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "del data, random_matrix, binary_tensor\n",
    "\n",
    "## Test LSTC-Tubal Model\n",
    "epsilon = 1e-3\n",
    "maxiter = 100\n",
    "pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "var = dense_tensor[pos_test]\n",
    "mape = np.zeros((7, 5, 3))\n",
    "rmse = np.zeros((7, 5, 3))\n",
    "\n",
    "for i in range(1, 7):\n",
    "    print('Graph partitioning: {}.'.format(2 ** i))\n",
    "    j = 0\n",
    "    for rho in [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]:\n",
    "        k = 0\n",
    "        for c in [1e-3, 1e-2, 1e-1]:\n",
    "            lambda0 = c * rho\n",
    "            tensor_hat = np.zeros(dense_tensor.shape)\n",
    "            if i == 0:\n",
    "                tensor_hat, _ = imputer(dense_tensor, sparse_tensor, rho, lambda0, epsilon, maxiter)\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            else:\n",
    "                road = graph_pems.values[:, i - 1]\n",
    "                for d in range(2 ** i):\n",
    "                    pos = np.where(road == d)\n",
    "                    dense = dense_tensor[pos[0], :, :]\n",
    "                    sparse = sparse_tensor[pos[0], :, :]\n",
    "                    small_tensor, _ = imputer(dense, sparse, rho, lambda0, epsilon, maxiter)\n",
    "                    tensor_hat[pos[0], :, :] = small_tensor\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            k += 1\n",
    "        j += 1\n",
    "        print('Final MAPE:')\n",
    "        print(mape[i, :, :])\n",
    "        print('Final RMSE:')\n",
    "        print(rmse[i, :, :])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-4w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 4 * 7]), 0)\n",
    "random_matrix = np.random.rand(data.values.shape[0], 4 * 7)\n",
    "\n",
    "missing_rate = 0.7\n",
    "\n",
    "### Non-random missing (NM) scenario:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[2]):\n",
    "        binary_tensor[i1, :, i2] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "del data, random_matrix, binary_tensor\n",
    "\n",
    "## Test LSTC-Tubal Model\n",
    "epsilon = 1e-3\n",
    "maxiter = 100\n",
    "pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "var = dense_tensor[pos_test]\n",
    "mape = np.zeros((7, 5, 3))\n",
    "rmse = np.zeros((7, 5, 3))\n",
    "\n",
    "for i in range(1, 7):\n",
    "    print('Graph partitioning: {}.'.format(2 ** i))\n",
    "    j = 0\n",
    "    for rho in [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]:\n",
    "        k = 0\n",
    "        for c in [1e-3, 1e-2, 1e-1]:\n",
    "            lambda0 = c * rho\n",
    "            tensor_hat = np.zeros(dense_tensor.shape)\n",
    "            if i == 0:\n",
    "                tensor_hat, _ = imputer(dense_tensor, sparse_tensor, rho, lambda0, epsilon, maxiter)\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            else:\n",
    "                road = graph_pems.values[:, i - 1]\n",
    "                for d in range(2 ** i):\n",
    "                    pos = np.where(road == d)\n",
    "                    dense = dense_tensor[pos[0], :, :]\n",
    "                    sparse = sparse_tensor[pos[0], :, :]\n",
    "                    small_tensor, _ = imputer(dense, sparse, rho, lambda0, epsilon, maxiter)\n",
    "                    tensor_hat[pos[0], :, :] = small_tensor\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            k += 1\n",
    "        j += 1\n",
    "        print('Final MAPE:')\n",
    "        print(mape[i, :, :])\n",
    "        print('Final RMSE:')\n",
    "        print(rmse[i, :, :])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>This work is released under the MIT license.</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
