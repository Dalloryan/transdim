{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-Tubal-Rank Smoothing Tensor Completion Imputer (LSTC-Tubal)\n",
    "\n",
    "This notebook shows how to implement a LSTC-Tubal imputer on some real-world large-scale data sets. To overcome the problem of missing values within multivariate time series data, this method takes into account both low-rank structure and time series regression. Meanwhile, to make the model scalable, we also integrate linear transform into the LATC model. For an in-depth discussion of LATC-Tubal-imputer, please see [1].\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<font color=\"black\">\n",
    "<b>[1]</b> Xinyu Chen, Yixian Chen, Lijun Sun (2020). <b>Scalable low-rank tensor learning for spatiotemporal traffic data imputation</b>. arXiv: 2008.03194. <a href=\"https://arxiv.org/abs/2008.03194\" title=\"PDF\"><b>[PDF]</b></a> <a href=\"https://doi.org/10.5281/zenodo.3939792\" title=\"data\"><b>[data]</b></a> \n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LATC-imputer kernel\n",
    "\n",
    "We start by introducing some necessary functions that relies on `Numpy`.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<ul>\n",
    "<li><b><code>ten2mat</code>:</b> <font color=\"black\">Unfold tensor as matrix by specifying mode.</font></li>\n",
    "<li><b><code>mat2ten</code>:</b> <font color=\"black\">Fold matrix as tensor by specifying dimension (i.e, tensor size) and mode.</font></li>\n",
    "<li><b><code>svt</code>:</b> <font color=\"black\">Implement the process of Singular Value Thresholding (SVT).</font></li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T11:06:30.415419Z",
     "start_time": "2021-01-30T11:06:30.150423Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ten2mat(tensor, mode):\n",
    "    return np.reshape(np.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1), order = 'F')\n",
    "\n",
    "def mat2ten(mat, dim, mode):\n",
    "    index = list()\n",
    "    index.append(mode)\n",
    "    for i in range(dim.shape[0]):\n",
    "        if i != mode:\n",
    "            index.append(i)\n",
    "    return np.moveaxis(np.reshape(mat, list(dim[index]), order = 'F'), 0, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T11:06:31.362423Z",
     "start_time": "2021-01-30T11:06:31.353441Z"
    }
   },
   "outputs": [],
   "source": [
    "def unitary_transform(tensor, Phi):\n",
    "    return np.einsum('kt, ijk -> ijt', Phi, tensor)\n",
    "\n",
    "def inv_unitary_transform(tensor, Phi):\n",
    "    return np.einsum('kt, ijt -> ijk', Phi, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T11:06:32.336419Z",
     "start_time": "2021-01-30T11:06:32.260421Z"
    }
   },
   "outputs": [],
   "source": [
    "def tsvt_unitary(tensor, Phi, tau):\n",
    "    dim = tensor.shape\n",
    "    X = np.zeros(dim)\n",
    "    tensor = unitary_transform(tensor, Phi)\n",
    "    for t in range(dim[2]):\n",
    "        u, s, v = np.linalg.svd(tensor[:, :, t], full_matrices = False)\n",
    "        r = len(np.where(s > tau)[0])\n",
    "        if r >= 1:\n",
    "            s = s[: r]\n",
    "            s[: r] = s[: r] - tau\n",
    "            X[:, :, t] = u[:, : r] @ np.diag(s) @ v[: r, :]\n",
    "    return inv_unitary_transform(X, Phi)\n",
    "\n",
    "from scipy.fftpack import dctn, idctn\n",
    "\n",
    "def tsvt_dct(tensor, tau):\n",
    "    dim = tensor.shape\n",
    "    X = np.zeros(dim)\n",
    "    tensor = dctn(tensor, axes = (2,), norm = 'ortho')\n",
    "    for t in range(dim[2]):\n",
    "        u, s, v = np.linalg.svd(tensor[:, :, t], full_matrices = False)\n",
    "        r = len(np.where(s > tau)[0])\n",
    "        if r >= 1:\n",
    "            s = s[: r]\n",
    "            s[: r] = s[: r] - tau\n",
    "            X[:, :, t] = u[:, : r] @ np.diag(s) @ v[: r, :]\n",
    "    return idctn(X, axes = (2,), norm = 'ortho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<ul>\n",
    "<li><b><code>compute_mape</code>:</b> <font color=\"black\">Compute the value of Mean Absolute Percentage Error (MAPE).</font></li>\n",
    "<li><b><code>compute_rmse</code>:</b> <font color=\"black\">Compute the value of Root Mean Square Error (RMSE).</font></li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "> Note that $$\\mathrm{MAPE}=\\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\left|y_{i}-\\hat{y}_{i}\\right|}{y_{i}} \\times 100, \\quad\\mathrm{RMSE}=\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}},$$ where $n$ is the total number of estimated values, and $y_i$ and $\\hat{y}_i$ are the actual value and its estimation, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T11:06:34.089420Z",
     "start_time": "2021-01-30T11:06:34.071423Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return  np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea behind LATC-imputer is to approximate partially observed data with both low-rank structure and time series dynamics. The following `imputer` kernel includes some necessary inputs:\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<ul>\n",
    "<li><b><code>dense_tensor</code>:</b> <font color=\"black\">This is an input which has the ground truth for validation. If this input is not available, you could use <code>dense_tensor = sparse_tensor.copy()</code> instead.</font></li>\n",
    "<li><b><code>sparse_tensor</code>:</b> <font color=\"black\">This is a partially observed tensor which has many missing entries.</font></li>\n",
    "<li><b><code>time_lags</code>:</b> <font color=\"black\">Time lags, e.g., <code>time_lags = np.array([1, 2, 3])</code>. </font></li>\n",
    "<li><b><code>alpha</code>:</b> <font color=\"black\">Weights for tensors' nuclear norm, e.g., <code>alpha = np.ones(3) / 3</code>. </font></li>\n",
    "<li><b><code>rho</code>:</b> <font color=\"black\">Learning rate for ADMM, e.g., <code>rho = 0.0005</code>. </font></li>\n",
    "<li><b><code>lambda0</code>:</b> <font color=\"black\">Weight for time series regressor, e.g., <code>lambda0 = 5 * rho</code>. If <code>lambda0 = 0</code>, then this imputer is actually a standard low-rank tensor completion (i.e., High-accuracy Low-Rank Tensor Completion, or HaLRTC).</font></li>\n",
    "<li><b><code>epsilon</code>:</b> <font color=\"black\">Stop criteria, e.g., <code>epsilon = 0.001</code>. </font></li>\n",
    "<li><b><code>maxiter</code>:</b> <font color=\"black\">Maximum iteration to stop algorithm, e.g., <code>maxiter = 50</code>. </font></li>\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T11:06:36.304422Z",
     "start_time": "2021-01-30T11:06:36.284421Z"
    }
   },
   "outputs": [],
   "source": [
    "def imputer(dense_tensor, sparse_tensor, rho0, lambda0, epsilon, maxiter, \n",
    "            sparse_Psi = True, transform = \"unitary\"):\n",
    "    \"\"\"Low-Tubal-Rank Smoothing Tensor Completion, LSTC-Tubal-imputer.\"\"\"\n",
    "    \n",
    "    dim = np.array(sparse_tensor.shape)\n",
    "    dt = np.int(np.prod(dim) / dim[0])\n",
    "    sparse_mat = ten2mat(sparse_tensor, 0)\n",
    "    pos_missing = np.where(sparse_mat == 0)\n",
    "    pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "    var = dense_tensor[pos_test]\n",
    "    \n",
    "    T = np.zeros(dim)                         # \\boldsymbol{\\mathcal{T}}\n",
    "    Z = sparse_mat.copy()                     # \\boldsymbol{Z}\n",
    "    Z[pos_missing] = np.mean(sparse_mat[sparse_mat != 0])\n",
    "    it = 0\n",
    "    last_mat = sparse_mat.copy()\n",
    "    snorm = np.linalg.norm(sparse_mat, 'fro')\n",
    "    del dense_tensor, sparse_tensor, sparse_mat\n",
    "    rho = rho0\n",
    "    Phis = []\n",
    "    if transform == \"unitary\":\n",
    "        temp1 = ten2mat(mat2ten(Z, dim, 0), 2)\n",
    "        _, Phi = np.linalg.eig(temp1 @ temp1.T)\n",
    "        Phis.append(Phi)\n",
    "        del temp1\n",
    "    if lambda0 > 0:\n",
    "        if sparse_Psi == True:\n",
    "            from scipy import sparse\n",
    "            from scipy.sparse.linalg import inv as inv\n",
    "            Psi1 = sparse.coo_matrix((np.ones(dt - 1), (np.arange(0, dt - 1), np.arange(0, dt - 1))), \n",
    "                                     shape = (dt - 1, dt)).tocsr()\n",
    "            Psi2 = sparse.coo_matrix((np.ones(dt - 1), (np.arange(0, dt - 1), np.arange(0, dt - 1) + 1)), \n",
    "                                     shape = (dt - 1, dt)).tocsr()\n",
    "            temp0 = Psi2 - Psi1\n",
    "            temp0 = temp0.T @ temp0\n",
    "            Imat = sparse.coo_matrix((np.ones(dt), (np.arange(0, dt), np.arange(0, dt))), shape = (dt, dt)).tocsr()\n",
    "            const = rho * inv(temp0 + rho * Imat / lambda0).todense() / lambda0\n",
    "        elif sparse_Psi == False:\n",
    "            Psi1 = np.append(np.eye(dt - 1), np.zeros((dt - 1, 1)), axis = 1)\n",
    "            Psi2 = np.append(np.zeros((dt - 1, 1)), np.eye(dt - 1), axis = 1)\n",
    "            temp0 = Psi2 - Psi1\n",
    "            temp0 = temp0.T @ temp0\n",
    "            const = rho * np.linalg.inv(temp0 + rho * np.eye(dt) / lambda0) / lambda0\n",
    "        del Psi1, Psi2, temp0\n",
    "    while True:\n",
    "        rho = min(rho * 1.05, 1e5)\n",
    "        if transform == \"unitary\":\n",
    "            X = tsvt_unitary(mat2ten(Z, dim, 0) - T / rho, Phi, 1 / rho)\n",
    "        elif transform == \"dct\":\n",
    "            X = tsvt_dct(mat2ten(Z, dim, 0) - T / rho, 1 / rho)\n",
    "        mat_hat = ten2mat(X, 0)\n",
    "        temp = ten2mat(X + T / rho, 0)\n",
    "        if lambda0 > 0:\n",
    "            Z[pos_missing] = (temp @ const)[pos_missing]\n",
    "        elif lambda0 == 0:\n",
    "            Z[pos_missing] = temp[pos_missing]\n",
    "        T = T + rho * (X - mat2ten(Z, dim, 0))\n",
    "        tol = np.linalg.norm((mat_hat - last_mat), 'fro') / snorm\n",
    "        last_mat = mat_hat.copy()\n",
    "        it += 1\n",
    "        if it % 10 == 0:\n",
    "            if transform == \"unitary\":\n",
    "                temp1 = ten2mat(mat2ten(Z, dim, 0) - T / rho, 2)\n",
    "                _, Phi = np.linalg.eig(temp1 @ temp1.T)\n",
    "                Phis.append(Phi)\n",
    "                del temp1\n",
    "        if (tol < epsilon) or (it >= maxiter):\n",
    "            break\n",
    "\n",
    "    return X, Phis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model with Graph Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the following codes to generate graph partitioning scheme.\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pymetis\n",
    "import pandas as pd\n",
    "\n",
    "def load_graph_data(pkl_filename):\n",
    "    sensor_ids, sensor_id_to_ind, adj_mx = load_pickle(pkl_filename)\n",
    "    return sensor_ids, sensor_id_to_ind, adj_mx\n",
    "\n",
    "def load_pickle(pickle_file):\n",
    "    try:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            pickle_data = pickle.load(f)\n",
    "    except UnicodeDecodeError as e:\n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            pickle_data = pickle.load(f, encoding='latin1')\n",
    "    except Exception as e:\n",
    "        print('Unable to load data ', pickle_file, ':', e)\n",
    "        raise\n",
    "    return pickle_data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sid, sind, adj = load_graph_data('adj_mat.pkl')\n",
    "    print(adj.shape)\n",
    "    adj_lst = []\n",
    "    part_pems = pd.DataFrame()\n",
    "    for i in range(len(adj)):\n",
    "        idx = np.setdiff1d(np.where(adj[i,:] > 0)[0], np.array([i]))\n",
    "        adj_lst.append(idx)\n",
    "    for k in [2, 4, 8, 16, 32, 64]:\n",
    "        cuts, labels = pymetis.part_graph(k, adjacency=adj_lst)\n",
    "        print(set(labels))\n",
    "        part_pems[str(k)] = labels\n",
    "    part_pems.to_csv('../datasets/California-data-set/graph_pems.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T11:06:39.791420Z",
     "start_time": "2021-01-30T11:06:39.211421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>16</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   2  4  8  16  32  64\n",
       "0  0  1  2   6   5  47\n",
       "1  0  1  2   6   5  47\n",
       "2  0  1  2   6   5  47\n",
       "3  0  1  2   6   5  47\n",
       "4  0  1  2   6   5  47"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "graph_pems = pd.read_csv('../datasets/California-data-set/graph_pems.csv')\n",
    "graph_pems.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-4w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 4 * 7]), 0)\n",
    "random_tensor = np.random.rand(data.values.shape[0], 288, 4 * 7)\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "### Random missing (RM)\n",
    "sparse_tensor = dense_tensor * np.round(random_tensor + 0.5 - missing_rate)\n",
    "del data, random_tensor\n",
    "\n",
    "## Test LSTC-Tubal Model\n",
    "epsilon = 1e-3\n",
    "maxiter = 100\n",
    "pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "var = dense_tensor[pos_test]\n",
    "mape = np.zeros((7, 3, 3))\n",
    "rmse = np.zeros((7, 3, 3))\n",
    "\n",
    "for i in range(1, 7):\n",
    "    print('Graph partitioning: {}.'.format(2 ** i))\n",
    "    j = 0\n",
    "    for rho in [1e-3, 5e-3, 1e-2]:\n",
    "        k = 0\n",
    "        for c in [1e-3, 1e-2, 1e-1]:\n",
    "            lambda0 = c * rho\n",
    "            tensor_hat = np.zeros(dense_tensor.shape)\n",
    "            if i == 0:\n",
    "                tensor_hat, _ = imputer(dense_tensor, sparse_tensor, rho, lambda0, epsilon, maxiter)\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            else:\n",
    "                road = graph_pems.values[:, i - 1]\n",
    "                for d in range(2 ** i):\n",
    "                    pos = np.where(road == d)\n",
    "                    dense = dense_tensor[pos[0], :, :]\n",
    "                    sparse = sparse_tensor[pos[0], :, :]\n",
    "                    small_tensor, _ = imputer(dense, sparse, rho, lambda0, epsilon, maxiter)\n",
    "                    tensor_hat[pos[0], :, :] = small_tensor\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            k += 1\n",
    "        j += 1\n",
    "    print('Final MAPE:')\n",
    "    print(mape[i, :, :])\n",
    "    print('Final RMSE:')\n",
    "    print(rmse[i, :, :])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-30T05:17:28.301990Z",
     "start_time": "2021-01-29T05:30:07.445642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph partitioning: 2.\n",
      "Final MAPE:\n",
      "[[0.02559145 0.02571864 0.02736457]\n",
      " [0.02708789 0.02683288 0.02586238]\n",
      " [0.0375385  0.03402267 0.02667263]]\n",
      "Final RMSE:\n",
      "[[2.31571756 2.3258735  2.45977911]\n",
      " [2.39595626 2.38275551 2.34027128]\n",
      " [3.10134414 2.85772349 2.39697255]]\n",
      "\n",
      "Graph partitioning: 4.\n",
      "Final MAPE:\n",
      "[[0.02677744 0.02686362 0.02805694]\n",
      " [0.02688619 0.02709273 0.02719683]\n",
      " [0.03170744 0.03010276 0.02658389]]\n",
      "Final RMSE:\n",
      "[[2.38256761 2.3902771  2.49259745]\n",
      " [2.38454787 2.39752796 2.42177358]\n",
      " [2.66629699 2.56699648 2.36706632]]\n",
      "\n",
      "Graph partitioning: 8.\n",
      "Final MAPE:\n",
      "[[0.02816056 0.02820276 0.02877879]\n",
      " [0.02795911 0.02783353 0.02805369]\n",
      " [0.03015453 0.02923842 0.02681856]]\n",
      "Final RMSE:\n",
      "[[2.469719   2.4739894  2.53136567]\n",
      " [2.45511797 2.44814194 2.47857669]\n",
      " [2.56836319 2.51259293 2.37408279]]\n",
      "\n",
      "Graph partitioning: 16.\n",
      "Final MAPE:\n",
      "[[0.02983293 0.02974203 0.02947013]\n",
      " [0.02976859 0.02961283 0.02909988]\n",
      " [0.03041097 0.02981774 0.02788668]]\n",
      "Final RMSE:\n",
      "[[2.58549285 2.58015406 2.57307289]\n",
      " [2.58148225 2.57142578 2.54603855]\n",
      " [2.60607205 2.56704691 2.44724407]]\n",
      "\n",
      "Graph partitioning: 32.\n",
      "Final MAPE:\n",
      "[[0.03136906 0.03108609 0.03027105]\n",
      " [0.03130521 0.03097903 0.03031543]\n",
      " [0.0315567  0.03102456 0.02903382]]\n",
      "Final RMSE:\n",
      "[[2.71066887 2.68949539 2.63605841]\n",
      " [2.70630159 2.68190876 2.63961489]\n",
      " [2.71330482 2.67436059 2.53656993]]\n",
      "\n",
      "Graph partitioning: 64.\n",
      "Final MAPE:\n",
      "[[0.03291425 0.03262446 0.03134747]\n",
      " [0.03288206 0.03252646 0.03095113]\n",
      " [0.03295281 0.03241335 0.03036638]]\n",
      "Final RMSE:\n",
      "[[2.85217944 2.82818219 2.73066432]\n",
      " [2.8498061  2.82100998 2.69978082]\n",
      " [2.84791272 2.80511672 2.65020958]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-4w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 4 * 7]), 0)\n",
    "random_tensor = np.random.rand(data.values.shape[0], 288, 4 * 7)\n",
    "\n",
    "missing_rate = 0.7\n",
    "\n",
    "### Random missing (RM)\n",
    "sparse_tensor = dense_tensor * np.round(random_tensor + 0.5 - missing_rate)\n",
    "del data, random_tensor\n",
    "\n",
    "## Test LSTC-Tubal Model\n",
    "epsilon = 1e-3\n",
    "maxiter = 100\n",
    "pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "var = dense_tensor[pos_test]\n",
    "mape = np.zeros((7, 3, 3))\n",
    "rmse = np.zeros((7, 3, 3))\n",
    "\n",
    "for i in range(1, 7):\n",
    "    print('Graph partitioning: {}.'.format(2 ** i))\n",
    "    j = 0\n",
    "    for rho in [1e-3, 5e-3, 1e-2]:\n",
    "        k = 0\n",
    "        for c in [1e-3, 1e-2, 1e-1]:\n",
    "            lambda0 = c * rho\n",
    "            tensor_hat = np.zeros(dense_tensor.shape)\n",
    "            if i == 0:\n",
    "                tensor_hat, _ = imputer(dense_tensor, sparse_tensor, rho, lambda0, epsilon, maxiter)\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            else:\n",
    "                road = graph_pems.values[:, i - 1]\n",
    "                for d in range(2 ** i):\n",
    "                    pos = np.where(road == d)\n",
    "                    dense = dense_tensor[pos[0], :, :]\n",
    "                    sparse = sparse_tensor[pos[0], :, :]\n",
    "                    small_tensor, _ = imputer(dense, sparse, rho, lambda0, epsilon, maxiter)\n",
    "                    tensor_hat[pos[0], :, :] = small_tensor\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            k += 1\n",
    "        j += 1\n",
    "    print('Final MAPE:')\n",
    "    print(mape[i, :, :])\n",
    "    print('Final RMSE:')\n",
    "    print(rmse[i, :, :])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-4w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 4 * 7]), 0)\n",
    "random_matrix = np.random.rand(data.values.shape[0], 4 * 7)\n",
    "\n",
    "missing_rate = 0.3\n",
    "\n",
    "### Non-random missing (NM) scenario:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[2]):\n",
    "        binary_tensor[i1, :, i2] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "del data, random_matrix, binary_tensor\n",
    "\n",
    "## Test LSTC-Tubal Model\n",
    "epsilon = 1e-3\n",
    "maxiter = 100\n",
    "pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "var = dense_tensor[pos_test]\n",
    "mape = np.zeros((7, 5, 3))\n",
    "rmse = np.zeros((7, 5, 3))\n",
    "\n",
    "for i in range(1, 7):\n",
    "    print('Graph partitioning: {}.'.format(2 ** i))\n",
    "    j = 0\n",
    "    for rho in [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]:\n",
    "        k = 0\n",
    "        for c in [1e-3, 1e-2, 1e-1]:\n",
    "            lambda0 = c * rho\n",
    "            tensor_hat = np.zeros(dense_tensor.shape)\n",
    "            if i == 0:\n",
    "                tensor_hat, _ = imputer(dense_tensor, sparse_tensor, rho, lambda0, epsilon, maxiter)\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            else:\n",
    "                road = graph_pems.values[:, i - 1]\n",
    "                for d in range(2 ** i):\n",
    "                    pos = np.where(road == d)\n",
    "                    dense = dense_tensor[pos[0], :, :]\n",
    "                    sparse = sparse_tensor[pos[0], :, :]\n",
    "                    small_tensor, _ = imputer(dense, sparse, rho, lambda0, epsilon, maxiter)\n",
    "                    tensor_hat[pos[0], :, :] = small_tensor\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            k += 1\n",
    "        j += 1\n",
    "    print('Final MAPE:')\n",
    "    print(mape[i, :, :])\n",
    "    print('Final RMSE:')\n",
    "    print(rmse[i, :, :])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-01T18:59:07.426249Z",
     "start_time": "2021-01-30T11:06:54.586423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph partitioning: 2.\n",
      "Final MAPE:\n",
      "[[0.06570153 0.06569398 0.06592662]\n",
      " [0.06584572 0.0658576  0.06615824]\n",
      " [0.07045194 0.0704494  0.07058429]\n",
      " [0.10147306 0.10145809 0.10136028]\n",
      " [0.11167958 0.11166415 0.11171363]]\n",
      "Final RMSE:\n",
      "[[5.05256578 5.05177715 5.06717345]\n",
      " [5.0551596  5.05562288 5.07327965]\n",
      " [5.31447771 5.31444403 5.32359923]\n",
      " [7.30792329 7.30736666 7.30436327]\n",
      " [7.95196926 7.95126142 7.9567187 ]]\n",
      "\n",
      "Graph partitioning: 4.\n",
      "Final MAPE:\n",
      "[[0.06516804 0.06516218 0.06531031]\n",
      " [0.06510132 0.06510016 0.06527516]\n",
      " [0.06705867 0.06705667 0.06736163]\n",
      " [0.09478097 0.09483806 0.09496056]\n",
      " [0.10782678 0.10780571 0.10792663]]\n",
      "Final RMSE:\n",
      "[[5.02221131 5.02110703 5.03066459]\n",
      " [5.01727421 5.01721791 5.0288955 ]\n",
      " [5.11350821 5.11342922 5.13103288]\n",
      " [6.89344134 6.8970904  6.90767343]\n",
      " [7.70151374 7.70050059 7.71076656]]\n",
      "\n",
      "Graph partitioning: 8.\n",
      "Final MAPE:\n",
      "[[0.06452292 0.06452317 0.0644468 ]\n",
      " [0.06434369 0.06431707 0.06449677]\n",
      " [0.06491473 0.06491194 0.06502643]\n",
      " [0.0864302  0.08643025 0.08708411]\n",
      " [0.10073071 0.10070189 0.10096003]]\n",
      "Final RMSE:\n",
      "[[4.99189013 4.9921156  4.98707563]\n",
      " [4.98031354 4.97828782 4.99060276]\n",
      " [5.00571368 5.00563843 5.01178173]\n",
      " [6.37158183 6.37174476 6.41559361]\n",
      " [7.26209663 7.26069033 7.27721346]]\n",
      "\n",
      "Graph partitioning: 16.\n",
      "Final MAPE:\n",
      "[[0.06440256 0.06441874 0.06439282]\n",
      " [0.06380626 0.06381179 0.06389707]\n",
      " [0.06398584 0.06398329 0.06406877]\n",
      " [0.0794877  0.07966413 0.07967814]\n",
      " [0.09370684 0.09381172 0.09424094]]\n",
      "Final RMSE:\n",
      "[[4.99520968 4.99573158 4.99321666]\n",
      " [4.95568734 4.9550174  4.95943594]\n",
      " [4.96494726 4.96287652 4.96718155]\n",
      " [5.93511271 5.94686662 5.95046099]\n",
      " [6.8445747  6.85179062 6.88204361]]\n",
      "\n",
      "Graph partitioning: 32.\n",
      "Final MAPE:\n",
      "[[0.06372706 0.06368391 0.06362472]\n",
      " [0.06248885 0.06251392 0.06268043]\n",
      " [0.06259136 0.06261729 0.06274026]\n",
      " [0.07373054 0.07389472 0.07405241]\n",
      " [0.08649644 0.08650775 0.08685074]]\n",
      "Final RMSE:\n",
      "[[4.96617483 4.96408651 4.96031632]\n",
      " [4.88373844 4.88587117 4.89523542]\n",
      " [4.89018554 4.89174181 4.89735551]\n",
      " [5.55254932 5.56359333 5.5747578 ]\n",
      " [6.41345406 6.4143782  6.43752834]]\n",
      "\n",
      "Graph partitioning: 64.\n",
      "Final MAPE:\n",
      "[[0.06302635 0.06300839 0.06286173]\n",
      " [0.06144077 0.06143098 0.0615548 ]\n",
      " [0.06139819 0.06137979 0.0616029 ]\n",
      " [0.06965677 0.06969703 0.07002557]\n",
      " [0.08068639 0.0807331  0.08103864]]\n",
      "Final RMSE:\n",
      "[[4.94740329 4.94615651 4.93605793]\n",
      " [4.83923132 4.83809934 4.84321881]\n",
      " [4.83730835 4.83429047 4.84558104]\n",
      " [5.3000269  5.30245706 5.32374412]\n",
      " [6.06721145 6.07058275 6.09263869]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(1000)\n",
    "\n",
    "data = pd.read_csv('../datasets/California-data-set/pems-4w.csv', header = None)\n",
    "dense_tensor = mat2ten(data.values, np.array([data.values.shape[0], 288, 4 * 7]), 0)\n",
    "random_matrix = np.random.rand(data.values.shape[0], 4 * 7)\n",
    "\n",
    "missing_rate = 0.7\n",
    "\n",
    "### Non-random missing (NM) scenario:\n",
    "binary_tensor = np.zeros(dense_tensor.shape)\n",
    "for i1 in range(dense_tensor.shape[0]):\n",
    "    for i2 in range(dense_tensor.shape[2]):\n",
    "        binary_tensor[i1, :, i2] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_tensor = np.multiply(dense_tensor, binary_tensor)\n",
    "del data, random_matrix, binary_tensor\n",
    "\n",
    "## Test LSTC-Tubal Model\n",
    "epsilon = 1e-3\n",
    "maxiter = 100\n",
    "pos_test = np.where((dense_tensor != 0) & (sparse_tensor == 0))\n",
    "var = dense_tensor[pos_test]\n",
    "mape = np.zeros((7, 5, 3))\n",
    "rmse = np.zeros((7, 5, 3))\n",
    "\n",
    "for i in range(1, 7):\n",
    "    print('Graph partitioning: {}.'.format(2 ** i))\n",
    "    j = 0\n",
    "    for rho in [1e-4, 5e-4, 1e-3, 5e-3, 1e-2]:\n",
    "        k = 0\n",
    "        for c in [1e-3, 1e-2, 1e-1]:\n",
    "            lambda0 = c * rho\n",
    "            tensor_hat = np.zeros(dense_tensor.shape)\n",
    "            if i == 0:\n",
    "                tensor_hat, _ = imputer(dense_tensor, sparse_tensor, rho, lambda0, epsilon, maxiter)\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            else:\n",
    "                road = graph_pems.values[:, i - 1]\n",
    "                for d in range(2 ** i):\n",
    "                    pos = np.where(road == d)\n",
    "                    dense = dense_tensor[pos[0], :, :]\n",
    "                    sparse = sparse_tensor[pos[0], :, :]\n",
    "                    small_tensor, _ = imputer(dense, sparse, rho, lambda0, epsilon, maxiter)\n",
    "                    tensor_hat[pos[0], :, :] = small_tensor\n",
    "                mape[i, j, k] = compute_mape(var, tensor_hat[pos_test])\n",
    "                rmse[i, j, k] = compute_rmse(var, tensor_hat[pos_test])\n",
    "            k += 1\n",
    "        j += 1\n",
    "    print('Final MAPE:')\n",
    "    print(mape[i, :, :])\n",
    "    print('Final RMSE:')\n",
    "    print(rmse[i, :, :])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>This work is released under the MIT license.</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
