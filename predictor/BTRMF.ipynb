{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Temporal Regularized Matrix Factorization\n",
    "\n",
    "**Published**: December 17, 2020\n",
    "\n",
    "**Revised**: December 23, 2020\n",
    "\n",
    "**Author**: Xinyu Chen [[**GitHub homepage**](https://github.com/xinychen)]\n",
    "\n",
    "**Download**: This Jupyter notebook is at our GitHub repository. If you want to evaluate the code, please download the notebook from the [**transdim**](https://github.com/xinychen/transdim/blob/master/imputer/BTMF.ipynb) repository.\n",
    "\n",
    "This notebook shows how to implement the Bayesian treatment for Temporal Regularized Matrix Factorization (BTRMF) on some real-world data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "We assume a spatiotemporal setting for multidimensional time series data throughout this work. In general, modern spatiotemporal data sets collected from sensor networks can be organized as matrix time series. For example, we can denote by matrix $Y\\in\\mathbb{R}^{N\\times T}$ a multivariate time series collected from $N$ locations/sensors on $T$ time points, with each row $$\\boldsymbol{y}_{i}=\\left(y_{i,1},y_{i,2},...,y_{i,t-1},y_{i,t},y_{i,t+1},...,y_{i,T}\\right)$$\n",
    "corresponding to the time series collected at location $i$.\n",
    "\n",
    "As mentioned, making accurate predictions on incomplete time series is very challenging, while missing data problem is almost inevitable in real-world applications. Figure 1 illustrates the prediction problem for incomplete time series data. Here we use $(i,t)\\in\\Omega$ to index the observed entries in matrix $Y$.\n",
    "\n",
    "<img src=\"../images/graphical_matrix_time_series.png\" alt=\"drawing\" width=\"500\"/>\n",
    "\n",
    "> **Figure 1**: Illustration of multivariate time series and the prediction problem in the presence of missing values (green: observed data; white: missing data; red: prediction).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Description\n",
    "\n",
    "- Gaussian observations:\n",
    "\n",
    "$$y_{it}\\sim\\mathcal{N}\\left(\\boldsymbol{w}_{i}^{\\top}\\boldsymbol{x}_{t},\\tau_{i}^{-1}\\right),\\forall (i,t)\\in\\Omega$$\n",
    "\n",
    "- Prior distributions of factor matrices:\n",
    "\n",
    "$$\\boldsymbol{w}_{i}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{w},\\Lambda_{w}^{-1}\\right)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\boldsymbol{x}_{t}\\sim\\left\\{\\begin{array}{ll}\\mathcal{N}\\left(\\boldsymbol{0},\\Lambda_{x}^{-1}\\right), & \\text{if $t\\in\\{1,2,\\ldots,h_d\\}$,} \\\\ \\mathcal{N}\\left(\\sum_{k=1}^{d}\\text{diag}(\\boldsymbol{\\theta}_{k})\\boldsymbol{x}_{t-h_k},\\Lambda_{x}^{-1}\\right),& \\text{otherwise}.\\end{array}\\right.$$\n",
    "\n",
    "- Conjugate priors:\n",
    "\n",
    "$$\\boldsymbol{\\mu}_{w}\\mid\\Lambda_{w}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{0},\\left(\\beta_0\\Lambda_{w}\\right)^{-1}\\right),\\Lambda_{w}\\sim\\mathcal{W}\\left(W_0,\\nu_0\\right)$$\n",
    "\n",
    "$$\\boldsymbol{\\theta}_{k}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{\\theta},\\Lambda_{\\theta}^{-1}\\right),\\boldsymbol{\\mu}_{\\theta}\\mid\\Lambda_{\\theta}\\sim\\mathcal{N}\\left(\\boldsymbol{\\mu}_{0},\\left(\\beta_0\\Lambda_{\\theta}\\right)^{-1}\\right),\\Lambda_{\\theta}\\sim\\mathcal{W}\\left(W_0,\\nu_0\\right)$$\n",
    "\n",
    "$$\\Lambda_{x}\\sim\\mathcal{W}\\left(W_0,\\nu_0\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv as inv\n",
    "from numpy.random import normal as normrnd\n",
    "from scipy.linalg import khatri_rao as kr_prod\n",
    "from scipy.stats import wishart\n",
    "from numpy.linalg import solve as solve\n",
    "from scipy.linalg import cholesky as cholesky_upper\n",
    "from scipy.linalg import solve_triangular as solve_ut\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvnrnd_pre(mu, Lambda):\n",
    "    src = normrnd(size = (mu.shape[0],))\n",
    "    return solve_ut(cholesky_upper(Lambda, overwrite_a = True, check_finite = False), \n",
    "                    src, lower = False, check_finite = False, overwrite_b = True) + mu\n",
    "\n",
    "def cov_mat(mat, mat_bar):\n",
    "    mat = mat - mat_bar\n",
    "    return mat.T @ mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_factor_w(tau_sparse_mat, tau_ind, W, X, tau, beta0 = 1, vargin = 0):\n",
    "    \"\"\"Sampling N-by-R factor matrix W and its hyperparameters (mu_w, Lambda_w).\"\"\"\n",
    "    \n",
    "    dim1, rank = W.shape\n",
    "    W_bar = np.mean(W, axis = 0)\n",
    "    temp = dim1 / (dim1 + beta0)\n",
    "    var_W_hyper = inv(np.eye(rank) + cov_mat(W, W_bar) + temp * beta0 * np.outer(W_bar, W_bar))\n",
    "    var_Lambda_hyper = wishart.rvs(df = dim1 + rank, scale = var_W_hyper)\n",
    "    var_mu_hyper = mvnrnd_pre(temp * W_bar, (dim1 + beta0) * var_Lambda_hyper)\n",
    "    \n",
    "    if dim1 * rank ** 2 > 1e+8:\n",
    "        vargin = 1\n",
    "    \n",
    "    if vargin == 0:\n",
    "        var1 = X.T\n",
    "        var2 = kr_prod(var1, var1)\n",
    "        var3 = (var2 @ tau_ind.T).reshape([rank, rank, dim1]) + var_Lambda_hyper[:, :, None]\n",
    "        var4 = var1 @ tau_sparse_mat.T + (var_Lambda_hyper @ var_mu_hyper)[:, None]\n",
    "        for i in range(dim1):\n",
    "            W[i, :] = mvnrnd_pre(solve(var3[:, :, i], var4[:, i]), var3[:, :, i])\n",
    "    elif vargin == 1:\n",
    "        for i in range(dim1):\n",
    "            pos0 = np.where(sparse_mat[i, :] != 0)\n",
    "            Xt = X[pos0[0], :]\n",
    "            var_mu = tau[i] * Xt.T @ sparse_mat[i, pos0[0]] + var_Lambda_hyper @ var_mu_hyper\n",
    "            var_Lambda = tau[i] * Xt.T @ Xt + var_Lambda_hyper\n",
    "            W[i, :] = mvnrnd_pre(solve(var_Lambda, var_mu), var_Lambda)\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_theta(X, theta, Lambda_x, time_lags, beta0 = 1):\n",
    "    \n",
    "    dim, rank = X.shape\n",
    "    d = time_lags.shape[0]\n",
    "    tmax = np.max(time_lags)\n",
    "    theta_bar = np.mean(theta, axis = 0)\n",
    "    temp = d / (d + beta0)\n",
    "    var_theta_hyper = inv(np.eye(rank) + cov_mat(theta, theta_bar) \n",
    "                          + temp * beta0 * np.outer(theta_bar, theta_bar))\n",
    "    var_Lambda_hyper = wishart.rvs(df = d + rank, scale = var_theta_hyper)\n",
    "    var_mu_hyper = mvnrnd_pre(temp * theta_bar, (d + beta0) * var_Lambda_hyper)\n",
    "    \n",
    "    for k in range(d):\n",
    "        theta0 = theta.copy()\n",
    "        theta0[k, :] = 0\n",
    "        mat0 = np.zeros((dim - tmax, rank))\n",
    "        for L in range(d):\n",
    "            mat0 += X[tmax - time_lags[L] : dim - time_lags[L], :] @ np.diag(theta0[L, :])\n",
    "        varPi = X[tmax : dim, :] - mat0\n",
    "        var0 = X[tmax - time_lags[k] : dim - time_lags[k], :]\n",
    "        var = np.einsum('ij, jk, ik -> j', var0, Lambda_x, varPi)\n",
    "        var_Lambda = np.einsum('ti, tj, ij -> ij', var0, var0, Lambda_x) + var_Lambda_hyper\n",
    "        theta[k, :] = mvnrnd_pre(solve(var_Lambda, var + var_Lambda_hyper @ var_mu_hyper), var_Lambda)\n",
    "        \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Likelihood $\\boldsymbol{x}_{t}\\sim\\left\\{\\begin{array}{ll}\\mathcal{N}\\left(\\boldsymbol{0},\\Lambda_{x}^{-1}\\right), & \\text{if $t\\in\\{1,2,\\ldots,h_d\\}$,} \\\\ \\mathcal{N}\\left(\\sum_{k=1}^{d}\\text{diag}(\\boldsymbol{\\theta}_{k})\\boldsymbol{x}_{t-h_k},\\Lambda_{x}^{-1}\\right),& \\text{otherwise},\\end{array}\\right.$:\n",
    "\n",
    "$$\\ln\\mathcal{L}\\left(\\boldsymbol{x}_{1},\\ldots,\\boldsymbol{x}_{T}\\mid\\boldsymbol{\\theta}_{1},\\ldots,\\boldsymbol{\\theta}_{d},\\Lambda_{x}\\right)$$\n",
    "\n",
    "$$\\propto\\frac{T}{2}\\ln\\left|\\Lambda_{x}\\right|-\\frac{1}{2}\\text{tr}\\left(\\Lambda_{x}\\sum_{t=1}^{h_d}\\boldsymbol{x}_{t}\\boldsymbol{x}_{t}^{\\top}+\\Lambda_{x}\\sum_{t=h_d+1}^{T}\\left(\\boldsymbol{x}_{t}-\\sum_{k}\\text{diag}(\\boldsymbol{\\theta}_{k})\\boldsymbol{x}_{t-h_k}\\right)\\left(\\boldsymbol{x}_{t}-\\sum_{k}\\text{diag}(\\boldsymbol{\\theta}_{k})\\boldsymbol{x}_{t-h_k}\\right)^\\top\\right)$$\n",
    "\n",
    "- Prior distribution $\\Lambda_{x}\\sim\\mathcal{W}\\left(S_0,\\nu_0\\right)$ where $\\nu_0\\geq R$:\n",
    "\n",
    "$$\\ln p\\left(\\Lambda_x\\mid S_0,\\nu_0\\right)\\propto\\frac{1}{2}(\\nu_0-R-1)\\ln\\left|\\Lambda_{x}\\right|-\\frac{1}{2}\\text{tr}\\left(\\Lambda_{x}S_0^{-1}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_Lambda_x(X, theta, time_lags):\n",
    "    \n",
    "    dim, rank = X.shape\n",
    "    d = time_lags.shape[0]\n",
    "    tmax = np.max(time_lags)\n",
    "    mat = X[: tmax, :].T @ X[: tmax, :]\n",
    "    temp = np.zeros((dim - tmax, rank, d))\n",
    "    for k in range(d):\n",
    "        temp[:, :, k] = X[tmax - time_lags[k] : dim - time_lags[k], :]\n",
    "    new_mat = X[tmax : dim, :] - np.einsum('kr, irk -> ir', theta, temp)\n",
    "    Lambda_x = wishart.rvs(df = dim + rank, scale = inv(np.eye(rank) + mat + new_mat.T @ new_mat))\n",
    "    \n",
    "    return Lambda_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_factor_x(tau_sparse_mat, tau_ind, time_lags, W, X, theta, Lambda_x):\n",
    "    \"\"\"Sampling T-by-R factor matrix X.\"\"\"\n",
    "\n",
    "    dim2, rank = X.shape\n",
    "    tmax = np.max(time_lags)\n",
    "    tmin = np.min(time_lags)\n",
    "    d = time_lags.shape[0]\n",
    "    A = np.zeros((d * rank, rank))\n",
    "    for k in range(d):\n",
    "        A[k * rank : (k + 1) * rank, :] = np.diag(theta[k, :])\n",
    "    A0 = np.dstack([A] * d)\n",
    "    for k in range(d):\n",
    "        A0[k * rank : (k + 1) * rank, :, k] = 0\n",
    "    mat0 = Lambda_x @ A.T\n",
    "    mat1 = np.einsum('kij, jt -> kit', A.reshape([d, rank, rank]), Lambda_x)\n",
    "    mat2 = np.einsum('kit, kjt -> ij', mat1, A.reshape([d, rank, rank]))\n",
    "    \n",
    "    var1 = W.T\n",
    "    var2 = kr_prod(var1, var1)\n",
    "    var3 = (var2 @ tau_ind).reshape([rank, rank, dim2]) + Lambda_x[:, :, None]\n",
    "    var4 = var1 @ tau_sparse_mat\n",
    "    for t in range(dim2):\n",
    "        Mt = np.zeros((rank, rank))\n",
    "        Nt = np.zeros(rank)\n",
    "        Qt = mat0 @ X[t - time_lags, :].reshape(rank * d)\n",
    "        index = list(range(0, d))\n",
    "        if t >= dim2 - tmax and t < dim2 - tmin:\n",
    "            index = list(np.where(t + time_lags < dim2))[0]\n",
    "        elif t < tmax:\n",
    "            Qt = np.zeros(rank)\n",
    "            index = list(np.where(t + time_lags >= tmax))[0]\n",
    "        if t < dim2 - tmin:\n",
    "            Mt = mat2.copy()\n",
    "            temp = np.zeros((rank * d, len(index)))\n",
    "            n = 0\n",
    "            for k in index:\n",
    "                temp[:, n] = X[t + time_lags[k] - time_lags, :].reshape(rank * d)\n",
    "                n += 1\n",
    "            temp0 = X[t + time_lags[index], :].T - np.einsum('ijk, ik -> jk', A0[:, :, index], temp)\n",
    "            Nt = np.einsum('kij, jk -> i', mat1[index, :, :], temp0)\n",
    "        \n",
    "        var3[:, :, t] = var3[:, :, t] + Mt\n",
    "        if t < tmax:\n",
    "            var3[:, :, t] = var3[:, :, t] - Lambda_x + np.eye(rank)\n",
    "        X[t, :] = mvnrnd_pre(solve(var3[:, :, t], var4[:, t] + Nt + Qt), var3[:, :, t])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_precision_tau(sparse_mat, mat_hat, ind):\n",
    "    var_alpha = 1e-6 + 0.5 * np.sum(ind, axis = 1)\n",
    "    var_beta = 1e-6 + 0.5 * np.sum(((sparse_mat - mat_hat) ** 2) * ind, axis = 1)\n",
    "    return np.random.gamma(var_alpha, 1 / var_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mape(var, var_hat):\n",
    "    return np.sum(np.abs(var - var_hat) / var) / var.shape[0]\n",
    "\n",
    "def compute_rmse(var, var_hat):\n",
    "    return  np.sqrt(np.sum((var - var_hat) ** 2) / var.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ar4cast(theta, X, Lambda_x, time_lags, multi_step):\n",
    "    dim, rank = X.shape\n",
    "    d = time_lags.shape[0]\n",
    "    X_new = np.append(X, np.zeros((multi_step, rank)), axis = 0)\n",
    "    for t in range(multi_step):\n",
    "        X_new[dim + t, :] = mvnrnd_pre(np.einsum('kr, kr -> r', theta, X_new[dim + t - time_lags, :]), Lambda_x)\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BTRMF Implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BTRMF(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter, multi_step = 1):\n",
    "    \"\"\"Bayesian Temporal Regularized Matrix Factorization, BTRMF.\"\"\"\n",
    "    \n",
    "    dim1, dim2 = sparse_mat.shape\n",
    "    d = time_lags.shape[0]\n",
    "    W = init[\"W\"]\n",
    "    X = init[\"X\"]\n",
    "    theta = 0.01 * np.random.randn(d, rank)\n",
    "    if np.isnan(sparse_mat).any() == False:\n",
    "        ind = sparse_mat != 0\n",
    "        pos_obs = np.where(ind)\n",
    "        pos_test = np.where((dense_mat != 0) & (sparse_mat == 0))\n",
    "    elif np.isnan(sparse_mat).any() == True:\n",
    "        pos_test = np.where((dense_mat != 0) & (np.isnan(sparse_mat)))\n",
    "        ind = ~np.isnan(sparse_mat)\n",
    "        pos_obs = np.where(ind)\n",
    "        sparse_mat[np.isnan(sparse_mat)] = 0\n",
    "    dense_test = dense_mat[pos_test]\n",
    "    del dense_mat\n",
    "    ind = sparse_mat != 0\n",
    "    tau = np.ones(dim1)\n",
    "    W_plus = np.zeros((dim1, rank, gibbs_iter))\n",
    "    theta_plus = np.zeros((d, rank, gibbs_iter))\n",
    "    tau_plus = np.zeros((dim1, gibbs_iter))\n",
    "    Lambda_plus = np.zeros((rank, rank, gibbs_iter))\n",
    "    temp_hat = np.zeros(len(pos_test[0]))\n",
    "    show_iter = 500\n",
    "    mat_hat_plus = np.zeros((dim1, dim2))\n",
    "    X_plus = np.zeros((dim2 + multi_step, rank, gibbs_iter))\n",
    "    mat_new_plus = np.zeros((dim1, multi_step))\n",
    "    for it in range(burn_iter + gibbs_iter):\n",
    "        tau_ind = tau[:, None] * ind\n",
    "        tau_sparse_mat = tau[:, None] * sparse_mat\n",
    "        W = sample_factor_w(tau_sparse_mat, tau_ind, W, X, tau, beta0 = 1, vargin = 0)\n",
    "        Lambda_x = sample_Lambda_x(X, theta, time_lags)\n",
    "        theta = sample_theta(X, theta, Lambda_x, time_lags)\n",
    "        X = sample_factor_x(tau_sparse_mat, tau_ind, time_lags, W, X, theta, Lambda_x)\n",
    "        mat_hat = W @ X.T\n",
    "        tau = sample_precision_tau(sparse_mat, mat_hat, ind)\n",
    "        temp_hat += mat_hat[pos_test]\n",
    "        if (it + 1) % show_iter == 0 and it < burn_iter:\n",
    "            temp_hat = temp_hat / show_iter\n",
    "            print('Iter: {}'.format(it + 1))\n",
    "            print('MAPE: {:.6}'.format(compute_mape(dense_test, temp_hat)))\n",
    "            print('RMSE: {:.6}'.format(compute_rmse(dense_test, temp_hat)))\n",
    "            temp_hat = np.zeros(len(pos_test[0]))\n",
    "            print()\n",
    "        if it + 1 > burn_iter:\n",
    "            W_plus[:, :, it - burn_iter] = W\n",
    "            theta_plus[:, :, it - burn_iter] = theta\n",
    "            Lambda_plus[:, :, it - burn_iter] = Lambda_x\n",
    "            tau_plus[:, it - burn_iter] = tau\n",
    "            mat_hat_plus += mat_hat\n",
    "            X0 = ar4cast(theta, X, Lambda_x, time_lags, multi_step)\n",
    "            X_plus[:, :, it - burn_iter] = X0\n",
    "            mat_new_plus += W @ X0[dim2 : dim2 + multi_step, :].T\n",
    "    mat_hat = mat_hat_plus / gibbs_iter\n",
    "    print('Imputation MAPE: {:.6}'.format(compute_mape(dense_test, mat_hat[:, : dim2][pos_test])))\n",
    "    print('Imputation RMSE: {:.6}'.format(compute_rmse(dense_test, mat_hat[:, : dim2][pos_test])))\n",
    "    print()\n",
    "    mat_hat = np.append(mat_hat, mat_new_plus / gibbs_iter, axis = 1)\n",
    "    mat_hat[mat_hat < 0] = 0\n",
    "    \n",
    "    return mat_hat, W_plus, X_plus, theta_plus, Lambda_plus, tau_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_factor_x_partial(tau_sparse_mat, tau_ind, time_lags, W, X, theta, Lambda_x, back_step):\n",
    "    \"\"\"Sampling T-by-R factor matrix X.\"\"\"\n",
    "    \n",
    "    dim2, rank = X.shape\n",
    "    tmax = np.max(time_lags)\n",
    "    tmin = np.min(time_lags)\n",
    "    d = time_lags.shape[0]\n",
    "    A = np.zeros((d * rank, rank))\n",
    "    for k in range(d):\n",
    "        A[k * rank : (k + 1) * rank, :] = np.diag(theta[k, :])\n",
    "    A0 = np.dstack([A] * d)\n",
    "    for k in range(d):\n",
    "        A0[k * rank : (k + 1) * rank, :, k] = 0\n",
    "    mat0 = Lambda_x @ A.T\n",
    "    mat1 = np.einsum('kij, jt -> kit', A.reshape([d, rank, rank]), Lambda_x)\n",
    "    mat2 = np.einsum('kit, kjt -> ij', mat1, A.reshape([d, rank, rank]))\n",
    "    \n",
    "    var1 = W.T\n",
    "    var2 = kr_prod(var1, var1)\n",
    "    var3 = (var2 @ tau_ind[:, - back_step :]).reshape([rank, rank, back_step]) + Lambda_x[:, :, None]\n",
    "    var4 = var1 @ tau_sparse_mat[:, - back_step :]\n",
    "    for t in range(dim2 - back_step, dim2):\n",
    "        Mt = np.zeros((rank, rank))\n",
    "        Nt = np.zeros(rank)\n",
    "        Qt = mat0 @ X[t - time_lags, :].reshape(rank * d)\n",
    "        index = list(range(0, d))\n",
    "        if t >= dim2 - tmax and t < dim2 - tmin:\n",
    "            index = list(np.where(t + time_lags < dim2))[0]\n",
    "        if t < dim2 - tmin:\n",
    "            Mt = mat2.copy()\n",
    "            temp = np.zeros((rank * d, len(index)))\n",
    "            n = 0\n",
    "            for k in index:\n",
    "                temp[:, n] = X[t + time_lags[k] - time_lags, :].reshape(rank * d)\n",
    "                n += 1\n",
    "            temp0 = X[t + time_lags[index], :].T - np.einsum('ijk, ik -> jk', A0[:, :, index], temp)\n",
    "            Nt = np.einsum('kij, jk -> i', mat1[index, :, :], temp0)\n",
    "        var3[:, :, t + back_step - dim2] = var3[:, :, t + back_step - dim2] + Mt\n",
    "        X[t, :] = mvnrnd_pre(solve(var3[:, :, t + back_step - dim2], \n",
    "                                   var4[:, t + back_step - dim2] + Nt + Qt), var3[:, :, t + back_step - dim2])\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BTRMF_partial(dense_mat, sparse_mat, init, rank, time_lags, burn_iter, gibbs_iter, multi_step = 1):\n",
    "    \n",
    "    dim1, dim2 = sparse_mat.shape\n",
    "    W_plus = init[\"W_plus\"]\n",
    "    X_plus = init[\"X_plus\"]\n",
    "    theta_plus = init[\"theta_plus\"]\n",
    "    Lambda_plus = init[\"Lambda_plus\"]\n",
    "    tau_plus = init[\"tau_plus\"]\n",
    "    ind = sparse_mat != 0\n",
    "    pos_obs = np.where(ind)\n",
    "    X_new_plus = np.zeros((dim2 + multi_step, rank, gibbs_iter))\n",
    "    mat_new_plus = np.zeros((dim1, multi_step))\n",
    "    back_step = 10 * multi_step\n",
    "    for it in range(gibbs_iter):\n",
    "        tau_ind = tau_plus[:, it][:, None] * ind\n",
    "        tau_sparse_mat = tau_plus[:, it][:, None] * sparse_mat\n",
    "        X = sample_factor_x_partial(tau_sparse_mat, tau_ind, time_lags, W_plus[:, :, it], \n",
    "                                    X_plus[:, :, it], theta_plus[:, :, it], Lambda_plus[:, :, it], back_step)\n",
    "        X0 = ar4cast(theta_plus[:, :, it], X, Lambda_plus[:, :, it], time_lags, multi_step)\n",
    "        X_new_plus[:, :, it] = X0\n",
    "        mat_new_plus += W_plus[:, :, it] @ X0[- multi_step :, :].T\n",
    "    mat_hat = mat_new_plus / gibbs_iter\n",
    "    mat_hat[mat_hat < 0] = 0\n",
    "    \n",
    "    return mat_hat, W_plus, X_new_plus, theta_plus, Lambda_plus, tau_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "def BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter):\n",
    "    T = dense_mat.shape[1]\n",
    "    start_time = T - pred_step\n",
    "    dim1 = dense_mat.shape[0]\n",
    "    max_count = int(np.ceil(pred_step / multi_step))\n",
    "    mat_hat = np.zeros((dim1, max_count * multi_step))\n",
    "    f = IntProgress(min = 0, max = max_count) # instantiate the bar\n",
    "    display(f) # display the bar\n",
    "    for t in range(max_count):\n",
    "        if t == 0:\n",
    "            init = {\"W\": 0.1 * np.random.randn(dim1, rank), \"X\": 0.1 * np.random.randn(start_time, rank)}\n",
    "            mat, W, X_new, theta, Lambda_x, tau = BTRMF(dense_mat[:, 0 : start_time], \n",
    "                sparse_mat[:, 0 : start_time], init, rank, time_lags, burn_iter, gibbs_iter, multi_step)\n",
    "        else:\n",
    "            init = {\"W_plus\": W, \"X_plus\": X_new, \"theta_plus\": theta, \"Lambda_plus\": Lambda_x, \"tau_plus\": tau}\n",
    "            mat, W, X_new, theta, Lambda_x, tau = BTRMF_partial(dense_mat[:, 0 : start_time + t * multi_step], \n",
    "                sparse_mat[:, 0 : start_time + t * multi_step], init, rank, time_lags, \n",
    "                                                        burn_iter, gibbs_iter, multi_step)\n",
    "        mat_hat[:, t * multi_step : (t + 1) * multi_step] = mat[:, - multi_step :]\n",
    "        f.value = t\n",
    "    small_dense_mat = dense_mat[:, start_time : dense_mat.shape[1]]\n",
    "    pos = np.where(small_dense_mat != 0)\n",
    "    print('Prediction MAPE: {:.6}'.format(compute_mape(small_dense_mat[pos], mat_hat[pos])))\n",
    "    print('Prediction RMSE: {:.6}'.format(compute_rmse(small_dense_mat[pos], mat_hat[pos])))\n",
    "    print()\n",
    "    return mat_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Guangzhou Speed Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $214\\times 61\\times 144$ (road segment, day, time of day)\n",
    "- Test on original data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "sparse_mat = dense_mat.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 144\n",
    "- Time lags: {1, 2, 144, 144 + 1, 144 + 2, 7 * 144, 7 * 144 + 1, 7 * 144 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time horizon (delta) = 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022f59827a5544dfa233d543f228eff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=504)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Imputation MAPE: nan\n",
      "Imputation RMSE: nan\n",
      "\n",
      "Prediction MAPE: 0.113683\n",
      "Prediction RMSE: 4.57707\n",
      "\n",
      "Running time: 2947 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 4.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e769c671d1f544cbb23db82e5f0e7d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=252)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Imputation MAPE: nan\n",
      "Imputation RMSE: nan\n",
      "\n",
      "Prediction MAPE: 0.118136\n",
      "Prediction RMSE: 4.7547\n",
      "\n",
      "Running time: 2377 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 6.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae7a898931c485ca9e91bff0bb3f859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=168)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Imputation MAPE: nan\n",
      "Imputation RMSE: nan\n",
      "\n",
      "Prediction MAPE: 0.123447\n",
      "Prediction RMSE: 4.94011\n",
      "\n",
      "Running time: 2188 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 12.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987fdbaec8724d789a2e3d5208352c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=84)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Imputation MAPE: nan\n",
      "Imputation RMSE: nan\n",
      "\n",
      "Prediction MAPE: 0.145856\n",
      "Prediction RMSE: 5.90556\n",
      "\n",
      "Running time: 1912 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 18.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853f770cbf074feaa00258966bf3ae0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=56)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Imputation MAPE: nan\n",
      "Imputation RMSE: nan\n",
      "\n",
      "Prediction MAPE: 0.146342\n",
      "Prediction RMSE: 5.90134\n",
      "\n",
      "Running time: 1929 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 24.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1cc363642e749d58ee32cfd9af651e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=42)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Imputation MAPE: nan\n",
      "Imputation RMSE: nan\n",
      "\n",
      "Prediction MAPE: 0.143891\n",
      "Prediction RMSE: 5.73838\n",
      "\n",
      "Running time: 1856 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 30.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a77feb03c304e5ca35b648b96243c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=34)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Imputation MAPE: nan\n",
      "Imputation RMSE: nan\n",
      "\n",
      "Prediction MAPE: 0.146586\n",
      "Prediction RMSE: 5.78402\n",
      "\n",
      "Running time: 1856 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 36.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975ecc34b9ee4237b0fab9dde02c1765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=28)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: nan\n",
      "RMSE: nan\n",
      "\n",
      "Imputation MAPE: nan\n",
      "Imputation RMSE: nan\n",
      "\n",
      "Prediction MAPE: 0.174528\n",
      "Prediction RMSE: 7.10779\n",
      "\n",
      "Running time: 1958 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 144\n",
    "time_lags = np.array([1, 2, 3, 144, 145, 146, 7 * 144, 7 * 144 + 1, 7 * 144 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6, 12, 18, 24, 30, 36]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $214\\times 61\\times 144$ (road segment, day, time of day)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_matrix.mat')['random_matrix']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_tensor = np.zeros(tensor.shape)\n",
    "for i1 in range(tensor.shape[0]):\n",
    "    for i2 in range(tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] * binary_tensor.shape[2]])\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 144\n",
    "- Time lags: {1, 2, 144, 144 + 1, 144 + 2, 7 * 144, 7 * 144 + 1, 7 * 144 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time horizon (delta) = 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2183ae1c7ecc4a64a8b731919d821153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=504)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.102551\n",
      "RMSE: 4.36767\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.103652\n",
      "RMSE: 4.57921\n",
      "\n",
      "Imputation MAPE: 0.104067\n",
      "Imputation RMSE: 4.71913\n",
      "\n",
      "Prediction MAPE: 0.119942\n",
      "Prediction RMSE: 4.7698\n",
      "\n",
      "Running time: 2890 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 4.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7ac1bf8ce74de4ad0ef3ffb238ab43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=252)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.102063\n",
      "RMSE: 4.32435\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.102245\n",
      "RMSE: 4.33657\n",
      "\n",
      "Imputation MAPE: 0.102214\n",
      "Imputation RMSE: 4.33442\n",
      "\n",
      "Prediction MAPE: 0.122606\n",
      "Prediction RMSE: 4.93322\n",
      "\n",
      "Running time: 2278 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 6.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94ad5a63d8d4a60b59dc964ecb2c6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=168)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.102254\n",
      "RMSE: 4.33556\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.102241\n",
      "RMSE: 4.33627\n",
      "\n",
      "Imputation MAPE: 0.102264\n",
      "Imputation RMSE: 4.3372\n",
      "\n",
      "Prediction MAPE: 0.12957\n",
      "Prediction RMSE: 5.19038\n",
      "\n",
      "Running time: 2090 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 12.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98768d0ee31461ab97a538a87b89368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=84)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.102164\n",
      "RMSE: 4.33312\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.102223\n",
      "RMSE: 4.33568\n",
      "\n",
      "Imputation MAPE: 0.102332\n",
      "Imputation RMSE: 4.33852\n",
      "\n",
      "Prediction MAPE: 0.146054\n",
      "Prediction RMSE: 5.8759\n",
      "\n",
      "Running time: 1921 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 18.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7594c0a7618e404ea615da0aaa7c6017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=56)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.102062\n",
      "RMSE: 4.3295\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.102284\n",
      "RMSE: 4.33875\n",
      "\n",
      "Imputation MAPE: 0.10222\n",
      "Imputation RMSE: 4.33367\n",
      "\n",
      "Prediction MAPE: 0.162287\n",
      "Prediction RMSE: 6.57395\n",
      "\n",
      "Running time: 1869 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 24.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b53ed4745a4ef7bb9dc93ca24301a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=42)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.103346\n",
      "RMSE: 4.43913\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.103448\n",
      "RMSE: 4.47035\n",
      "\n",
      "Imputation MAPE: 0.103053\n",
      "Imputation RMSE: 4.46833\n",
      "\n",
      "Prediction MAPE: 0.145759\n",
      "Prediction RMSE: 5.72347\n",
      "\n",
      "Running time: 1846 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 30.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93a856a3f614ddeae2e9bbea2ea4bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=34)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.102372\n",
      "RMSE: 4.33869\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.102496\n",
      "RMSE: 4.34821\n",
      "\n",
      "Imputation MAPE: 0.1023\n",
      "Imputation RMSE: 4.33981\n",
      "\n",
      "Prediction MAPE: 0.168842\n",
      "Prediction RMSE: 6.84068\n",
      "\n",
      "Running time: 1829 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 36.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476c23a8a6754e849e9b0198f4a8092b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=28)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.102427\n",
      "RMSE: 4.34408\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.102474\n",
      "RMSE: 4.34794\n",
      "\n",
      "Imputation MAPE: 0.102382\n",
      "Imputation RMSE: 4.34278\n",
      "\n",
      "Prediction MAPE: 0.14108\n",
      "Prediction RMSE: 5.46894\n",
      "\n",
      "Running time: 1829 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 144\n",
    "time_lags = np.array([1, 2, 3, 144, 145, 146, 7 * 144, 7 * 144 + 1, 7 * 144 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6, 12, 18, 24, 30, 36]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $214\\times 61\\times 144$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')['random_tensor']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_mat = (np.round(random_tensor + 0.5 - missing_rate)\n",
    "              .reshape([random_tensor.shape[0], random_tensor.shape[1] * random_tensor.shape[2]]))\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 144\n",
    "- Time lags: {1, 2, 144, 144 + 1, 144 + 2, 7 * 144, 7 * 144 + 1, 7 * 144 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time horizon (delta) = 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91e29f25bf84496b98f7fb99fcbad7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=504)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.0986118\n",
      "RMSE: 4.16984\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0985913\n",
      "RMSE: 4.17064\n",
      "\n",
      "Imputation MAPE: 0.0986026\n",
      "Imputation RMSE: 4.17141\n",
      "\n",
      "Prediction MAPE: 0.114071\n",
      "Prediction RMSE: 4.56949\n",
      "\n",
      "Running time: 3381 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 4.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08189cf108ad4c8482d1e2ed41157deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=252)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.098629\n",
      "RMSE: 4.17203\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0986091\n",
      "RMSE: 4.17289\n",
      "\n",
      "Imputation MAPE: 0.0986195\n",
      "Imputation RMSE: 4.17455\n",
      "\n",
      "Prediction MAPE: 0.116732\n",
      "Prediction RMSE: 4.66984\n",
      "\n",
      "Running time: 2550 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 6.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5edd4dde6f446f4ab0cd8a7723033b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=168)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.0987062\n",
      "RMSE: 4.17503\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0987199\n",
      "RMSE: 4.17563\n",
      "\n",
      "Imputation MAPE: 0.0987252\n",
      "Imputation RMSE: 4.17566\n",
      "\n",
      "Prediction MAPE: 0.124486\n",
      "Prediction RMSE: 4.9962\n",
      "\n",
      "Running time: 2276 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 12.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d203f5b9134360a31f74122d651bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=84)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.098544\n",
      "RMSE: 4.16577\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0986339\n",
      "RMSE: 4.17173\n",
      "\n",
      "Imputation MAPE: 0.0986256\n",
      "Imputation RMSE: 4.1715\n",
      "\n",
      "Prediction MAPE: 0.138936\n",
      "Prediction RMSE: 5.52781\n",
      "\n",
      "Running time: 2014 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 18.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442ddf40e48c4ce0ae34b5259f5ace52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=56)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.0985256\n",
      "RMSE: 4.16895\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0985908\n",
      "RMSE: 4.17392\n",
      "\n",
      "Imputation MAPE: 0.0986125\n",
      "Imputation RMSE: 4.1749\n",
      "\n",
      "Prediction MAPE: 0.14166\n",
      "Prediction RMSE: 5.60551\n",
      "\n",
      "Running time: 1929 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 24.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bd309ad401483b954d9c20b1948d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=42)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.0985505\n",
      "RMSE: 4.16709\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0985932\n",
      "RMSE: 4.17026\n",
      "\n",
      "Imputation MAPE: 0.0985927\n",
      "Imputation RMSE: 4.16987\n",
      "\n",
      "Prediction MAPE: 0.141169\n",
      "Prediction RMSE: 5.54439\n",
      "\n",
      "Running time: 1893 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 30.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfe81f2076e443897ab1d8165bfd836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=34)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.0985609\n",
      "RMSE: 4.16711\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0986802\n",
      "RMSE: 4.17507\n",
      "\n",
      "Imputation MAPE: 0.0987116\n",
      "Imputation RMSE: 4.17666\n",
      "\n",
      "Prediction MAPE: 0.137951\n",
      "Prediction RMSE: 5.39165\n",
      "\n",
      "Running time: 1879 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 36.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd87980436247259e3ec7eba24bd596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=28)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.0985261\n",
      "RMSE: 4.16671\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0986298\n",
      "RMSE: 4.17334\n",
      "\n",
      "Imputation MAPE: 0.0986251\n",
      "Imputation RMSE: 4.17341\n",
      "\n",
      "Prediction MAPE: 0.145925\n",
      "Prediction RMSE: 5.77936\n",
      "\n",
      "Running time: 1858 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 144\n",
    "time_lags = np.array([1, 2, 3, 144, 145, 146, 7 * 144, 7 * 144 + 1, 7 * 144 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6, 12, 18, 24, 30, 36]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $214\\times 61\\times 144$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 60% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Guangzhou-data-set/random_tensor.mat')['random_tensor']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.6\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_mat = (np.round(random_tensor + 0.5 - missing_rate)\n",
    "              .reshape([random_tensor.shape[0], random_tensor.shape[1] * random_tensor.shape[2]]))\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 144\n",
    "- Time lags: {1, 2, 144, 144 + 1, 144 + 2, 7 * 144, 7 * 144 + 1, 7 * 144 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time horizon (delta) = 2.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7375c82fb612499985952ba2a1b7d7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=504)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.0997617\n",
      "RMSE: 4.20035\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0999632\n",
      "RMSE: 4.21554\n",
      "\n",
      "Imputation MAPE: 0.100029\n",
      "Imputation RMSE: 4.21733\n",
      "\n",
      "Prediction MAPE: 0.116847\n",
      "Prediction RMSE: 4.66734\n",
      "\n",
      "Running time: 3349 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 4.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da30c647737a4e6b8ee5e73cd1dc86f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=252)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.0997897\n",
      "RMSE: 4.20511\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0999748\n",
      "RMSE: 4.21601\n",
      "\n",
      "Imputation MAPE: 0.0999896\n",
      "Imputation RMSE: 4.21673\n",
      "\n",
      "Prediction MAPE: 0.122342\n",
      "Prediction RMSE: 4.82326\n",
      "\n",
      "Running time: 2558 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 6.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da7b90597b84a5c9a32651ada9ae43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=168)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.0999046\n",
      "RMSE: 4.21086\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.0999454\n",
      "RMSE: 4.21481\n",
      "\n",
      "Imputation MAPE: 0.0999657\n",
      "Imputation RMSE: 4.21483\n",
      "\n",
      "Prediction MAPE: 0.126441\n",
      "Prediction RMSE: 5.00543\n",
      "\n",
      "Running time: 2323 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 12.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34506efb3cb438486816e94677d74ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=84)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 500\n",
      "MAPE: 0.099831\n",
      "RMSE: 4.20667\n",
      "\n",
      "Iter: 1000\n",
      "MAPE: 0.099951\n",
      "RMSE: 4.21453\n",
      "\n",
      "Imputation MAPE: 0.0999973\n",
      "Imputation RMSE: 4.21626\n",
      "\n",
      "Prediction MAPE: 0.133589\n",
      "Prediction RMSE: 5.31734\n",
      "\n",
      "Running time: 2122 seconds\n",
      "\n",
      "Prediction time horizon (delta) = 18.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3001efa24eac4f83a21402c0956fd041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=56)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 144\n",
    "time_lags = np.array([1, 2, 3, 144, 145, 146, 7 * 144, 7 * 144 + 1, 7 * 144 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6, 12, 18, 24, 30, 36]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Hangzhou Flow Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $80\\times 25\\times 108$ (metro station, day, time of day)\n",
    "- Test on original data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')['tensor']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "sparse_mat = dense_mat.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 108\n",
    "- Time lags: {1, 2, 108, 108 + 1, 108 + 2, 7 * 108, 7 * 108 + 1, 7 * 108 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 108\n",
    "time_lags = np.array([1, 2, 3, 108, 109, 110, 7 * 108, 7 * 108 + 1, 7 * 108 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $80\\times 25\\times 108$ (metro station, day, time of day)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')['tensor']\n",
    "random_matrix = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_matrix.mat')['random_matrix']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_tensor = np.zeros(tensor.shape)\n",
    "for i1 in range(tensor.shape[0]):\n",
    "    for i2 in range(tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(random_matrix[i1, i2] + 0.5 - missing_rate)\n",
    "binary_mat = binary_tensor.reshape([binary_tensor.shape[0], binary_tensor.shape[1] * binary_tensor.shape[2]])\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 108\n",
    "- Time lags: {1, 2, 108, 108 + 1, 108 + 2, 7 * 108, 7 * 108 + 1, 7 * 108 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 108\n",
    "time_lags = np.array([1, 2, 3, 108, 109, 110, 7 * 108, 7 * 108 + 1, 7 * 108 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $80\\times 25\\times 108$ (metro station, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')['random_tensor']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_mat = (np.round(random_tensor + 0.5 - missing_rate)\n",
    "              .reshape([random_tensor.shape[0], random_tensor.shape[1] * random_tensor.shape[2]]))\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 108\n",
    "- Time lags: {1, 2, 108, 108 + 1, 108 + 2, 7 * 108, 7 * 108 + 1, 7 * 108 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 108\n",
    "time_lags = np.array([1, 2, 3, 108, 109, 110, 7 * 108, 7 * 108 + 1, 7 * 108 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $80\\times 25\\times 108$ (metro station, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 60% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "\n",
    "tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/tensor.mat')['tensor']\n",
    "random_tensor = scipy.io.loadmat('../datasets/Hangzhou-data-set/random_tensor.mat')['random_tensor']\n",
    "dense_mat = tensor.reshape([tensor.shape[0], tensor.shape[1] * tensor.shape[2]])\n",
    "missing_rate = 0.6\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_mat = (np.round(random_tensor + 0.5 - missing_rate)\n",
    "              .reshape([random_tensor.shape[0], random_tensor.shape[1] * random_tensor.shape[2]]))\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 108\n",
    "- Time lags: {1, 2, 108, 108 + 1, 108 + 2, 7 * 108, 7 * 108 + 1, 7 * 108 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 108\n",
    "time_lags = np.array([1, 2, 3, 108, 109, 110, 7 * 108, 7 * 108 + 1, 7 * 108 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Seattle Speed Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $323\\times 28\\times 288$ (road segment, day, time of day)\n",
    "- Test on original data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "sparse_mat = dense_mat.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 288\n",
    "- Time lags: {1, 2, 288, 288 + 1, 288 + 2, 7 * 288, 7 * 288 + 1, 7 * 288 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 288\n",
    "time_lags = np.array([1, 2, 3, 288, 289, 290, 7 * 288, 7 * 288 + 1, 7 * 288 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $323\\times 28\\times 288$ (road segment, day, time of day)\n",
    "- Non-random missing (NM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "NM_mat = pd.read_csv('../datasets/Seattle-data-set/NM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "NM_mat = NM_mat.values\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_tensor = np.zeros((dense_mat.shape[0], 28, 288))\n",
    "for i1 in range(binary_tensor.shape[0]):\n",
    "    for i2 in range(binary_tensor.shape[1]):\n",
    "        binary_tensor[i1, i2, :] = np.round(NM_mat[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, binary_tensor.reshape([dense_mat.shape[0], dense_mat.shape[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 288\n",
    "- Time lags: {1, 2, 288, 288 + 1, 288 + 2, 7 * 288, 7 * 288 + 1, 7 * 288 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 288\n",
    "time_lags = np.array([1, 2, 3, 288, 289, 290, 7 * 288, 7 * 288 + 1, 7 * 288 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $323\\times 28\\times 288$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 40% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "RM_mat = pd.read_csv('../datasets/Seattle-data-set/RM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "RM_mat = RM_mat.values\n",
    "missing_rate = 0.4\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_mat = np.round(RM_mat + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 288\n",
    "- Time lags: {1, 2, 288, 288 + 1, 288 + 2, 7 * 288, 7 * 288 + 1, 7 * 288 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 288\n",
    "time_lags = np.array([1, 2, 3, 288, 289, 290, 7 * 288, 7 * 288 + 1, 7 * 288 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario setting**:\n",
    "\n",
    "- Tensor size: $323\\times 28\\times 288$ (road segment, day, time of day)\n",
    "- Random missing (RM)\n",
    "- 60% missing rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dense_mat = pd.read_csv('../datasets/Seattle-data-set/mat.csv', index_col = 0)\n",
    "RM_mat = pd.read_csv('../datasets/Seattle-data-set/RM_mat.csv', index_col = 0)\n",
    "dense_mat = dense_mat.values\n",
    "RM_mat = RM_mat.values\n",
    "missing_rate = 0.6\n",
    "\n",
    "## Random missing (RM)\n",
    "binary_mat = np.round(RM_mat + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 288\n",
    "- Time lags: {1, 2, 288, 288 + 1, 288 + 2, 7 * 288, 7 * 288 + 1, 7 * 288 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 288\n",
    "time_lags = np.array([1, 2, 3, 288, 289, 290, 7 * 288, 7 * 288 + 1, 7 * 288 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on London Movement Speed Data\n",
    "\n",
    "London movement speed data set is is a city-wide hourly traffic speeddataset collected in London.\n",
    "\n",
    "- Collected from 200,000+ road segments.\n",
    "- 720 time points in April 2019.\n",
    "- 73% missing values in the original data.\n",
    "\n",
    "|  Observation rate | $>90\\%$ | $>80\\%$ | $>70\\%$ | $>60\\%$ | $>50\\%$ |\n",
    "|:------------------|--------:|--------:|--------:|--------:|--------:|\n",
    "|**Number of roads**|  17,666 |  27,148 |  35,912 |  44,352 |  52,727 |\n",
    "\n",
    "\n",
    "If want to test on the full dataset, you could consider the following setting for masking observations as missing values. \n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "mask_rate = 0.20\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "pos_obs = np.where(dense_mat != 0)\n",
    "num = len(pos_obs[0])\n",
    "sample_ind = np.random.choice(num, size = int(mask_rate * num), replace = False)\n",
    "sparse_mat = dense_mat.copy()\n",
    "sparse_mat[pos_obs[0][sample_ind], pos_obs[1][sample_ind]] = 0\n",
    "```\n",
    "\n",
    "Notably, you could also consider to evaluate the model on a subset of the data with the following setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "sparse_mat = dense_mat.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 24\n",
    "- Time lags: {1, 2, 24, 24 + 1, 24 + 2, 7 * 24, 7 * 24 + 1, 7 * 24 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 24\n",
    "time_lags = np.array([1, 2, 3, 24, 25, 26, 7 * 24, 7 * 24 + 1, 7 * 24 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Non-random missing (NM)\n",
    "binary_mat = np.zeros(dense_mat.shape)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], 30)\n",
    "for i1 in range(dense_mat.shape[0]):\n",
    "    for i2 in range(30):\n",
    "        binary_mat[i1, i2 * 24 : (i2 + 1) * 24] = np.round(random_mat[i1, i2] + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 24\n",
    "- Time lags: {1, 2, 24, 24 + 1, 24 + 2, 7 * 24, 7 * 24 + 1, 7 * 24 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 24\n",
    "time_lags = np.array([1, 2, 3, 24, 25, 26, 7 * 24, 7 * 24 + 1, 7 * 24 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.4\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Random missing (RM)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], dense_mat.shape[1])\n",
    "binary_mat = np.round(random_mat + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 24\n",
    "- Time lags: {1, 2, 24, 24 + 1, 24 + 2, 7 * 24, 7 * 24 + 1, 7 * 24 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 24\n",
    "time_lags = np.array([1, 2, 3, 24, 25, 26, 7 * 24, 7 * 24 + 1, 7 * 24 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1000)\n",
    "\n",
    "missing_rate = 0.6\n",
    "\n",
    "dense_mat = np.load('../datasets/London-data-set/hourly_speed_mat.npy')\n",
    "binary_mat = dense_mat.copy()\n",
    "binary_mat[binary_mat != 0] = 1\n",
    "pos = np.where(np.sum(binary_mat, axis = 1) > 0.7 * binary_mat.shape[1])\n",
    "dense_mat = dense_mat[pos[0], :]\n",
    "\n",
    "## Random missing (RM)\n",
    "random_mat = np.random.rand(dense_mat.shape[0], dense_mat.shape[1])\n",
    "binary_mat = np.round(random_mat + 0.5 - missing_rate)\n",
    "sparse_mat = np.multiply(dense_mat, binary_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setting**:\n",
    "\n",
    "- Low rank: 10\n",
    "- Total (rolling) prediction horizons: 7 * 24\n",
    "- Time lags: {1, 2, 24, 24 + 1, 24 + 2, 7 * 24, 7 * 24 + 1, 7 * 24 + 2}\n",
    "- The number of burn-in iterations: 1000\n",
    "- The number of Gibbs iterations: 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "rank = 10\n",
    "pred_step = 7 * 24\n",
    "time_lags = np.array([1, 2, 3, 24, 25, 26, 7 * 24, 7 * 24 + 1, 7 * 24 + 2])\n",
    "burn_iter = 1000\n",
    "gibbs_iter = 200\n",
    "for multi_step in [2, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14]:\n",
    "    start = time.time()\n",
    "    print('Prediction time horizon (delta) = {}.'.format(multi_step))\n",
    "    mat_hat = BTRMF_forecast(dense_mat, sparse_mat, pred_step, multi_step, rank, time_lags, burn_iter, gibbs_iter)\n",
    "    end = time.time()\n",
    "    print('Running time: %d seconds'%(end - start))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>This work is released under the MIT license.</b>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
